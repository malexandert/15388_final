{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our project, we would like to collect data to see if voter preferences correlate to how affected certain populations were by the Great Recession. We can measure “recession effect” in a number of different ways. For example, we can use statistics from the US Bureau of Labor to map certain geographical areas, and we can compare statistics from pre-2008 and post-2008 to view how the recession affected jobs in those regions. From there, we could look at polls or voter data to see how those regions voted in either the 2010 midterm elections or the 2012 Presidential election. Comparing these two sets of data, we would be interested in finding out which parties/administrations people blamed more for the recession, and whether or not voting habits changed in areas most affected by the recession, and why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sounds good, but because political landscapes are changing constantly, it is difficult to assign certain changes as being \"caused\" to the 2008 recession as opposed to just brought on by other factors that happen to correlate with areas hit by the recession (the classic correlation/causation issue). But if you keep this fact in mind, then I think the analysis can be interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. recession effect data\n",
    "\t- industries effected by 08’ recession\n",
    "\t- recovery rate of effected industries (pre ’08 / post ’08 industry stats)\n",
    "\t- outsourcing in respective industries\n",
    "    - [BLS api](http://www.bls.gov/developers/api_signature_v2.htm#multiple)\n",
    "    - [BLS series](http://www.bls.gov/help/hlpforma.htm#OE)\n",
    "    - [BLS python API example](http://www.bls.gov/developers/api_python.htm#python2)\n",
    "2. voter preference data\n",
    "\t-  pre / post ’08\n",
    "3. find way to partition each data set geographically\n",
    "\t- west coast / midwest / east coast\n",
    "\t- rural / metropolitan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Election"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze the election data, we'll be looking towards [Politico](http://www.politico.com/) and the [New York Times](http://www.nytimes.com) and their election coverage pages. Unfortunately, due to formatting changes over the years, it's a little more difficult than we'd like it to be to fetch county voter data from the 2008, 2012, and 2016 elections with one script. However, it's not too hard to write scripts for each of those elections individually.\n",
    "\n",
    "To help us, we'll be using the [Selenium WebDriver API](http://selenium-python.readthedocs.io/) and [PhantomJS](http://phantomjs.org/) to GET some of the pages. You can install them like so (assuming you have a Mac and Homebrew)\n",
    "```\n",
    "pip install selenium\n",
    "brew install phantomjs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import sklearn\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "# List of states and D.C.\n",
    "states = [\n",
    "    'Alabama','Alaska','Arizona','Arkansas','California','Colorado',\n",
    "    'Connecticut','Delaware','District Of Columbia','Florida','Georgia','Hawaii','Idaho', \n",
    "    'Illinois','Indiana','Iowa','Kansas','Kentucky','Louisiana',\n",
    "    'Maine','Maryland','Massachusetts','Michigan','Minnesota',\n",
    "    'Mississippi', 'Missouri','Montana','Nebraska','Nevada',\n",
    "    'New Hampshire','New Jersey','New Mexico','New York',\n",
    "    'North Carolina','North Dakota','Ohio',    \n",
    "    'Oklahoma','Oregon','Pennsylvania','Rhode Island',\n",
    "    'South Carolina','South Dakota','Tennessee','Texas','Utah',\n",
    "    'Vermont','Virginia','Washington','West Virginia',\n",
    "    'Wisconsin','Wyoming'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll be collecting 2008 data from the New York Times page. In terms of formatting, we're hoping to get the year, state, county, and the number of votes for the Democratic and Republican parties (we'll be ignoring third-parties in this analysis). Since Alaska and Washington D.C. don't have counties, we'll just count the state (or district) itself as the county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Converts data taken from the table in the html\n",
    "    Input: a table row of voting data, in html\n",
    "    Output: a list of data in a more desirable format\n",
    "'''\n",
    "def voter_html_to_data_2008(voter_html):\n",
    "    data = [datum.get_text().strip() for datum in voter_html.find_all('td')]\n",
    "    blue_votes = int(data[2][:-5].replace(',',''))\n",
    "    red_votes = int(data[4][:-5].replace(',',''))\n",
    "    return [blue_votes, red_votes]\n",
    "\n",
    "def get_voter_data_2008():\n",
    "    # Set up our data frame\n",
    "    df = pd.DataFrame(columns=('election_year', 'state', 'dem_votes', 'rep_votes'))\n",
    "    \n",
    "    # Base url we'll be getting data from \n",
    "    base_url = 'http://elections.nytimes.com/2008/results/states/president/'\n",
    "    \n",
    "    # Get state names for url endings\n",
    "    state_urls = sorted([state.lower().replace(' ', '-') for state in states])\n",
    "\n",
    "    # Iterate through the states (except for Alaska and D.C.)\n",
    "    num_states = 0\n",
    "    for state in state_urls:\n",
    "        if state != 'alaska' and state != 'district-of-columbia':\n",
    "            # Get data from the site\n",
    "            response = requests.get(base_url + state + '.html')\n",
    "            election_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Data for all states except for Alaska and D.C.\n",
    "            data_rows = election_soup.find(id='winners-by-county-table').tbody.find_all('tr')\n",
    "            \n",
    "            # Data that every row will have (election year and state)\n",
    "            header_data = ['2008', state]\n",
    "            state_vote_lists = [voter_html_to_data_2008(row) for row in data_rows]\n",
    "            state_vote_counts = [sum([vote[0] for vote in state_vote_lists]), sum([vote[1] for vote in state_vote_lists])]\n",
    "            voter_data = header_data + state_vote_counts\n",
    "            df.loc[num_states] = voter_data\n",
    "            num_states += 1\n",
    "    \n",
    "    # Since Alaska and D.C. don't have counties, we process them slightly differently\n",
    "    # First, Alaska\n",
    "    alaska_html = requests.get('http://elections.nytimes.com/2008/results/states/alaska.html')\n",
    "    alaska_election_soup = BeautifulSoup(alaska_html.text, 'html.parser')\n",
    "    \n",
    "    alaska_obama = alaska_election_soup.find(id='presidential-results-table').tbody.find_all('tr')[:2][1].find_all('td')\n",
    "    alaska_mccain = alaska_election_soup.find(id='presidential-results-table').tbody.find_all('tr')[:2][0].find_all('td')\n",
    "    alaska_blue_votes = int(alaska_obama[1].get_text().strip().replace(',',''))\n",
    "    alaska_red_votes = int(alaska_mccain[2].get_text().strip().replace(',',''))\n",
    "    alaska_data = ['2008', 'alaska', alaska_blue_votes, alaska_red_votes]\n",
    "    df.loc[num_states] = alaska_data\n",
    "    num_states += 1\n",
    "    \n",
    "    # Finally, D.C.\n",
    "    dc_html = requests.get('http://elections.nytimes.com/2008/results/states/district-of-columbia.html')\n",
    "    dc_election_soup = BeautifulSoup(dc_html.text, 'html.parser')\n",
    "\n",
    "    dc_obama = dc_election_soup.find(id='presidential-results-table').tbody.find_all('tr')[:2][0].find_all('td')\n",
    "    dc_mccain = dc_election_soup.find(id='presidential-results-table').tbody.find_all('tr')[:2][1].find_all('td')\n",
    "    dc_blue_votes = int(dc_obama[2].get_text().strip().replace(',',''))\n",
    "    dc_red_votes = int(dc_mccain[1].get_text().strip().replace(',',''))\n",
    "    dc_data = ['2008', 'district-of-columbia', dc_blue_votes, dc_red_votes]\n",
    "    df.loc[num_states] = dc_data\n",
    "    num_states += 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    dem_votes  rep_votes\n",
      "election_year state                                     \n",
      "2008          alabama                811764.0  1264879.0\n",
      "              alaska                 122485.0   192631.0\n",
      "              arizona                948648.0  1132560.0\n",
      "              arkansas               418049.0   632672.0\n",
      "              california            7441458.0  4554643.0\n",
      "              colorado              1216793.0  1020135.0\n",
      "              connecticut            994320.0   627688.0\n",
      "              delaware               255394.0   152356.0\n",
      "              district-of-columbia   210403.0    14821.0\n",
      "              florida               4143957.0  3939380.0\n",
      "              georgia               1843452.0  2048244.0\n",
      "              hawaii                 324918.0   120309.0\n",
      "              idaho                  235219.0   400989.0\n",
      "              illinois              3319237.0  1981158.0\n",
      "              indiana               1367264.0  1341101.0\n",
      "              iowa                   818240.0   677508.0\n",
      "              kansas                 499979.0   685541.0\n",
      "              kentucky               746510.0  1043264.0\n",
      "              louisiana              780981.0  1147603.0\n",
      "              maine                  421481.0   296192.0\n",
      "              maryland              1612692.0   956663.0\n",
      "              massachusetts         1891083.0  1104284.0\n",
      "              michigan              2867680.0  2044405.0\n",
      "              minnesota             1573323.0  1275400.0\n",
      "              mississippi            520864.0   687266.0\n",
      "              missouri              1442180.0  1445812.0\n",
      "              montana                229725.0   241816.0\n",
      "              nebraska               329132.0   448801.0\n",
      "              nevada                 531884.0   411988.0\n",
      "              new-hampshire          384591.0   316937.0\n",
      "              new-jersey            2085051.0  1545495.0\n",
      "              new-mexico             458754.0   340857.0\n",
      "              new-york              4363386.0  2576360.0\n",
      "              north-carolina        2123390.0  2109698.0\n",
      "              north-dakota           141113.0   168523.0\n",
      "              ohio                  2708685.0  2501855.0\n",
      "              oklahoma               502294.0   959745.0\n",
      "              oregon                 978605.0   699673.0\n",
      "              pennsylvania          3192316.0  2586496.0\n",
      "              rhode-island           275488.0   152502.0\n",
      "              south-carolina         850121.0  1018756.0\n",
      "              south-dakota           170886.0   203019.0\n",
      "              tennessee             1081074.0  1470160.0\n",
      "              texas                 3521164.0  4467748.0\n",
      "              utah                   317063.0   568610.0\n",
      "              vermont                219105.0    98791.0\n",
      "              virginia              1958370.0  1726053.0\n",
      "              washington            1547632.0  1097176.0\n",
      "              west-virginia          301438.0   394278.0\n",
      "              wisconsin             1670474.0  1258181.0\n",
      "              wyoming                 80496.0   160639.0\n"
     ]
    }
   ],
   "source": [
    "df_2008 = get_voter_data_2008()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>election_year</th>\n",
       "      <th>state</th>\n",
       "      <th>dem_votes</th>\n",
       "      <th>rep_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>alabama</td>\n",
       "      <td>811764.0</td>\n",
       "      <td>1264879.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>arizona</td>\n",
       "      <td>948648.0</td>\n",
       "      <td>1132560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>arkansas</td>\n",
       "      <td>418049.0</td>\n",
       "      <td>632672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>california</td>\n",
       "      <td>7441458.0</td>\n",
       "      <td>4554643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>colorado</td>\n",
       "      <td>1216793.0</td>\n",
       "      <td>1020135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>994320.0</td>\n",
       "      <td>627688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2008</td>\n",
       "      <td>delaware</td>\n",
       "      <td>255394.0</td>\n",
       "      <td>152356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008</td>\n",
       "      <td>florida</td>\n",
       "      <td>4143957.0</td>\n",
       "      <td>3939380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008</td>\n",
       "      <td>georgia</td>\n",
       "      <td>1843452.0</td>\n",
       "      <td>2048244.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2008</td>\n",
       "      <td>hawaii</td>\n",
       "      <td>324918.0</td>\n",
       "      <td>120309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2008</td>\n",
       "      <td>idaho</td>\n",
       "      <td>235219.0</td>\n",
       "      <td>400989.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2008</td>\n",
       "      <td>illinois</td>\n",
       "      <td>3319237.0</td>\n",
       "      <td>1981158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2008</td>\n",
       "      <td>indiana</td>\n",
       "      <td>1367264.0</td>\n",
       "      <td>1341101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2008</td>\n",
       "      <td>iowa</td>\n",
       "      <td>818240.0</td>\n",
       "      <td>677508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2008</td>\n",
       "      <td>kansas</td>\n",
       "      <td>499979.0</td>\n",
       "      <td>685541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2008</td>\n",
       "      <td>kentucky</td>\n",
       "      <td>746510.0</td>\n",
       "      <td>1043264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2008</td>\n",
       "      <td>louisiana</td>\n",
       "      <td>780981.0</td>\n",
       "      <td>1147603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2008</td>\n",
       "      <td>maine</td>\n",
       "      <td>421481.0</td>\n",
       "      <td>296192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2008</td>\n",
       "      <td>maryland</td>\n",
       "      <td>1612692.0</td>\n",
       "      <td>956663.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2008</td>\n",
       "      <td>massachusetts</td>\n",
       "      <td>1891083.0</td>\n",
       "      <td>1104284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2008</td>\n",
       "      <td>michigan</td>\n",
       "      <td>2867680.0</td>\n",
       "      <td>2044405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2008</td>\n",
       "      <td>minnesota</td>\n",
       "      <td>1573323.0</td>\n",
       "      <td>1275400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2008</td>\n",
       "      <td>mississippi</td>\n",
       "      <td>520864.0</td>\n",
       "      <td>687266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2008</td>\n",
       "      <td>missouri</td>\n",
       "      <td>1442180.0</td>\n",
       "      <td>1445812.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2008</td>\n",
       "      <td>montana</td>\n",
       "      <td>229725.0</td>\n",
       "      <td>241816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2008</td>\n",
       "      <td>nebraska</td>\n",
       "      <td>329132.0</td>\n",
       "      <td>448801.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2008</td>\n",
       "      <td>nevada</td>\n",
       "      <td>531884.0</td>\n",
       "      <td>411988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2008</td>\n",
       "      <td>new-hampshire</td>\n",
       "      <td>384591.0</td>\n",
       "      <td>316937.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2008</td>\n",
       "      <td>new-jersey</td>\n",
       "      <td>2085051.0</td>\n",
       "      <td>1545495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2008</td>\n",
       "      <td>new-mexico</td>\n",
       "      <td>458754.0</td>\n",
       "      <td>340857.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2008</td>\n",
       "      <td>new-york</td>\n",
       "      <td>4363386.0</td>\n",
       "      <td>2576360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2008</td>\n",
       "      <td>north-carolina</td>\n",
       "      <td>2123390.0</td>\n",
       "      <td>2109698.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2008</td>\n",
       "      <td>north-dakota</td>\n",
       "      <td>141113.0</td>\n",
       "      <td>168523.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2008</td>\n",
       "      <td>ohio</td>\n",
       "      <td>2708685.0</td>\n",
       "      <td>2501855.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2008</td>\n",
       "      <td>oklahoma</td>\n",
       "      <td>502294.0</td>\n",
       "      <td>959745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2008</td>\n",
       "      <td>oregon</td>\n",
       "      <td>978605.0</td>\n",
       "      <td>699673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2008</td>\n",
       "      <td>pennsylvania</td>\n",
       "      <td>3192316.0</td>\n",
       "      <td>2586496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2008</td>\n",
       "      <td>rhode-island</td>\n",
       "      <td>275488.0</td>\n",
       "      <td>152502.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2008</td>\n",
       "      <td>south-carolina</td>\n",
       "      <td>850121.0</td>\n",
       "      <td>1018756.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2008</td>\n",
       "      <td>south-dakota</td>\n",
       "      <td>170886.0</td>\n",
       "      <td>203019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2008</td>\n",
       "      <td>tennessee</td>\n",
       "      <td>1081074.0</td>\n",
       "      <td>1470160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2008</td>\n",
       "      <td>texas</td>\n",
       "      <td>3521164.0</td>\n",
       "      <td>4467748.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2008</td>\n",
       "      <td>utah</td>\n",
       "      <td>317063.0</td>\n",
       "      <td>568610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2008</td>\n",
       "      <td>vermont</td>\n",
       "      <td>219105.0</td>\n",
       "      <td>98791.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2008</td>\n",
       "      <td>virginia</td>\n",
       "      <td>1958370.0</td>\n",
       "      <td>1726053.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2008</td>\n",
       "      <td>washington</td>\n",
       "      <td>1547632.0</td>\n",
       "      <td>1097176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2008</td>\n",
       "      <td>west-virginia</td>\n",
       "      <td>301438.0</td>\n",
       "      <td>394278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2008</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>1670474.0</td>\n",
       "      <td>1258181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2008</td>\n",
       "      <td>wyoming</td>\n",
       "      <td>80496.0</td>\n",
       "      <td>160639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2008</td>\n",
       "      <td>alaska</td>\n",
       "      <td>122485.0</td>\n",
       "      <td>192631.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2008</td>\n",
       "      <td>district-of-columbia</td>\n",
       "      <td>210403.0</td>\n",
       "      <td>14821.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   election_year                 state  dem_votes  rep_votes\n",
       "0           2008               alabama   811764.0  1264879.0\n",
       "1           2008               arizona   948648.0  1132560.0\n",
       "2           2008              arkansas   418049.0   632672.0\n",
       "3           2008            california  7441458.0  4554643.0\n",
       "4           2008              colorado  1216793.0  1020135.0\n",
       "5           2008           connecticut   994320.0   627688.0\n",
       "6           2008              delaware   255394.0   152356.0\n",
       "7           2008               florida  4143957.0  3939380.0\n",
       "8           2008               georgia  1843452.0  2048244.0\n",
       "9           2008                hawaii   324918.0   120309.0\n",
       "10          2008                 idaho   235219.0   400989.0\n",
       "11          2008              illinois  3319237.0  1981158.0\n",
       "12          2008               indiana  1367264.0  1341101.0\n",
       "13          2008                  iowa   818240.0   677508.0\n",
       "14          2008                kansas   499979.0   685541.0\n",
       "15          2008              kentucky   746510.0  1043264.0\n",
       "16          2008             louisiana   780981.0  1147603.0\n",
       "17          2008                 maine   421481.0   296192.0\n",
       "18          2008              maryland  1612692.0   956663.0\n",
       "19          2008         massachusetts  1891083.0  1104284.0\n",
       "20          2008              michigan  2867680.0  2044405.0\n",
       "21          2008             minnesota  1573323.0  1275400.0\n",
       "22          2008           mississippi   520864.0   687266.0\n",
       "23          2008              missouri  1442180.0  1445812.0\n",
       "24          2008               montana   229725.0   241816.0\n",
       "25          2008              nebraska   329132.0   448801.0\n",
       "26          2008                nevada   531884.0   411988.0\n",
       "27          2008         new-hampshire   384591.0   316937.0\n",
       "28          2008            new-jersey  2085051.0  1545495.0\n",
       "29          2008            new-mexico   458754.0   340857.0\n",
       "30          2008              new-york  4363386.0  2576360.0\n",
       "31          2008        north-carolina  2123390.0  2109698.0\n",
       "32          2008          north-dakota   141113.0   168523.0\n",
       "33          2008                  ohio  2708685.0  2501855.0\n",
       "34          2008              oklahoma   502294.0   959745.0\n",
       "35          2008                oregon   978605.0   699673.0\n",
       "36          2008          pennsylvania  3192316.0  2586496.0\n",
       "37          2008          rhode-island   275488.0   152502.0\n",
       "38          2008        south-carolina   850121.0  1018756.0\n",
       "39          2008          south-dakota   170886.0   203019.0\n",
       "40          2008             tennessee  1081074.0  1470160.0\n",
       "41          2008                 texas  3521164.0  4467748.0\n",
       "42          2008                  utah   317063.0   568610.0\n",
       "43          2008               vermont   219105.0    98791.0\n",
       "44          2008              virginia  1958370.0  1726053.0\n",
       "45          2008            washington  1547632.0  1097176.0\n",
       "46          2008         west-virginia   301438.0   394278.0\n",
       "47          2008             wisconsin  1670474.0  1258181.0\n",
       "48          2008               wyoming    80496.0   160639.0\n",
       "49          2008                alaska   122485.0   192631.0\n",
       "50          2008  district-of-columbia   210403.0    14821.0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 2012, it'll be easier to use the Politico pages to collect the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_voter_data_2012():\n",
    "    # Set up our data frame\n",
    "    df = pd.DataFrame(columns=('election_year', 'state', 'dem_votes', 'rep_votes'))\n",
    "    \n",
    "    # Base url we'll be getting data from\n",
    "    base_url = 'http://www.politico.com/2012-election/results/president/'\n",
    "    \n",
    "    # Get state names for url endings\n",
    "    state_urls = sorted([state.lower().replace(' ', '-') for state in states])\n",
    "    \n",
    "    # Once again, Alaska and D.C. are slightly different\n",
    "    num_states = 0\n",
    "    for state in state_urls:\n",
    "        # Get data from site\n",
    "        try:\n",
    "            response = requests.get(base_url + state + '/')\n",
    "        except ConnectionError:\n",
    "            time.sleep(2)\n",
    "            response = requests.get(base_url + state + '/')\n",
    "        election_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        header_data = ['2012', state]\n",
    "        data = election_soup.find('div', class_='state-results-macro').table.tbody\n",
    "        blue_votes = int(data.find(class_='party-democrat').find(class_='results-popular').get_text().strip().replace(',',''))\n",
    "        red_votes = int(data.find(class_='party-republican').find(class_='results-popular').get_text().strip().replace(',',''))\n",
    "        voter_data = header_data + [blue_votes, red_votes]\n",
    "        df.loc[num_states] = voter_data\n",
    "        num_states += 1\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_2012 = get_voter_data_2012()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>election_year</th>\n",
       "      <th>state</th>\n",
       "      <th>dem_votes</th>\n",
       "      <th>rep_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>alabama</td>\n",
       "      <td>793620.0</td>\n",
       "      <td>1252453.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>alaska</td>\n",
       "      <td>102138.0</td>\n",
       "      <td>136848.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>arizona</td>\n",
       "      <td>930669.0</td>\n",
       "      <td>1143051.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "      <td>arkansas</td>\n",
       "      <td>389699.0</td>\n",
       "      <td>638467.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>california</td>\n",
       "      <td>6493924.0</td>\n",
       "      <td>4202127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>colorado</td>\n",
       "      <td>1238490.0</td>\n",
       "      <td>1125391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>912531.0</td>\n",
       "      <td>631432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012</td>\n",
       "      <td>delaware</td>\n",
       "      <td>242547.0</td>\n",
       "      <td>165476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012</td>\n",
       "      <td>district-of-columbia</td>\n",
       "      <td>222332.0</td>\n",
       "      <td>17337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012</td>\n",
       "      <td>florida</td>\n",
       "      <td>4235270.0</td>\n",
       "      <td>4162081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2012</td>\n",
       "      <td>georgia</td>\n",
       "      <td>1761761.0</td>\n",
       "      <td>2070221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012</td>\n",
       "      <td>hawaii</td>\n",
       "      <td>303090.0</td>\n",
       "      <td>119494.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012</td>\n",
       "      <td>idaho</td>\n",
       "      <td>212560.0</td>\n",
       "      <td>420750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2012</td>\n",
       "      <td>illinois</td>\n",
       "      <td>2916811.0</td>\n",
       "      <td>2090116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2012</td>\n",
       "      <td>indiana</td>\n",
       "      <td>1140425.0</td>\n",
       "      <td>1412620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2012</td>\n",
       "      <td>iowa</td>\n",
       "      <td>816429.0</td>\n",
       "      <td>727928.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2012</td>\n",
       "      <td>kansas</td>\n",
       "      <td>427918.0</td>\n",
       "      <td>678719.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2012</td>\n",
       "      <td>kentucky</td>\n",
       "      <td>679340.0</td>\n",
       "      <td>1087127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2012</td>\n",
       "      <td>louisiana</td>\n",
       "      <td>808496.0</td>\n",
       "      <td>1152460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2012</td>\n",
       "      <td>maine</td>\n",
       "      <td>397754.0</td>\n",
       "      <td>290437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2012</td>\n",
       "      <td>maryland</td>\n",
       "      <td>1527686.0</td>\n",
       "      <td>904970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2012</td>\n",
       "      <td>massachusetts</td>\n",
       "      <td>1900575.0</td>\n",
       "      <td>1177370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2012</td>\n",
       "      <td>michigan</td>\n",
       "      <td>2561911.0</td>\n",
       "      <td>2112673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2012</td>\n",
       "      <td>minnesota</td>\n",
       "      <td>1547668.0</td>\n",
       "      <td>1321575.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2012</td>\n",
       "      <td>mississippi</td>\n",
       "      <td>528260.0</td>\n",
       "      <td>674302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2012</td>\n",
       "      <td>missouri</td>\n",
       "      <td>1215031.0</td>\n",
       "      <td>1478961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2012</td>\n",
       "      <td>montana</td>\n",
       "      <td>200489.0</td>\n",
       "      <td>264974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2012</td>\n",
       "      <td>nebraska</td>\n",
       "      <td>289154.0</td>\n",
       "      <td>462972.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2012</td>\n",
       "      <td>nevada</td>\n",
       "      <td>528801.0</td>\n",
       "      <td>462422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2012</td>\n",
       "      <td>new-hampshire</td>\n",
       "      <td>368529.0</td>\n",
       "      <td>327870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2012</td>\n",
       "      <td>new-jersey</td>\n",
       "      <td>1960744.0</td>\n",
       "      <td>1383233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2012</td>\n",
       "      <td>new-mexico</td>\n",
       "      <td>408312.0</td>\n",
       "      <td>331915.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2012</td>\n",
       "      <td>new-york</td>\n",
       "      <td>3875826.0</td>\n",
       "      <td>2226637.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2012</td>\n",
       "      <td>north-carolina</td>\n",
       "      <td>2178388.0</td>\n",
       "      <td>2275853.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2012</td>\n",
       "      <td>north-dakota</td>\n",
       "      <td>124490.0</td>\n",
       "      <td>187586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2012</td>\n",
       "      <td>ohio</td>\n",
       "      <td>2697260.0</td>\n",
       "      <td>2593779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2012</td>\n",
       "      <td>oklahoma</td>\n",
       "      <td>442647.0</td>\n",
       "      <td>889372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2012</td>\n",
       "      <td>oregon</td>\n",
       "      <td>937321.0</td>\n",
       "      <td>733743.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2012</td>\n",
       "      <td>pennsylvania</td>\n",
       "      <td>2907448.0</td>\n",
       "      <td>2619583.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2012</td>\n",
       "      <td>rhode-island</td>\n",
       "      <td>274342.0</td>\n",
       "      <td>155355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2012</td>\n",
       "      <td>south-carolina</td>\n",
       "      <td>845756.0</td>\n",
       "      <td>1049507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2012</td>\n",
       "      <td>south-dakota</td>\n",
       "      <td>144988.0</td>\n",
       "      <td>210541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2012</td>\n",
       "      <td>tennessee</td>\n",
       "      <td>953043.0</td>\n",
       "      <td>1453097.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2012</td>\n",
       "      <td>texas</td>\n",
       "      <td>3294440.0</td>\n",
       "      <td>4555799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2012</td>\n",
       "      <td>utah</td>\n",
       "      <td>229463.0</td>\n",
       "      <td>671747.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2012</td>\n",
       "      <td>vermont</td>\n",
       "      <td>199259.0</td>\n",
       "      <td>92700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2012</td>\n",
       "      <td>virginia</td>\n",
       "      <td>1905528.0</td>\n",
       "      <td>1789618.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2012</td>\n",
       "      <td>washington</td>\n",
       "      <td>1620432.0</td>\n",
       "      <td>1210369.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2012</td>\n",
       "      <td>west-virginia</td>\n",
       "      <td>234925.0</td>\n",
       "      <td>412406.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2012</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>1613950.0</td>\n",
       "      <td>1408746.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2012</td>\n",
       "      <td>wyoming</td>\n",
       "      <td>68780.0</td>\n",
       "      <td>170265.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   election_year                 state  dem_votes  rep_votes\n",
       "0           2012               alabama   793620.0  1252453.0\n",
       "1           2012                alaska   102138.0   136848.0\n",
       "2           2012               arizona   930669.0  1143051.0\n",
       "3           2012              arkansas   389699.0   638467.0\n",
       "4           2012            california  6493924.0  4202127.0\n",
       "5           2012              colorado  1238490.0  1125391.0\n",
       "6           2012           connecticut   912531.0   631432.0\n",
       "7           2012              delaware   242547.0   165476.0\n",
       "8           2012  district-of-columbia   222332.0    17337.0\n",
       "9           2012               florida  4235270.0  4162081.0\n",
       "10          2012               georgia  1761761.0  2070221.0\n",
       "11          2012                hawaii   303090.0   119494.0\n",
       "12          2012                 idaho   212560.0   420750.0\n",
       "13          2012              illinois  2916811.0  2090116.0\n",
       "14          2012               indiana  1140425.0  1412620.0\n",
       "15          2012                  iowa   816429.0   727928.0\n",
       "16          2012                kansas   427918.0   678719.0\n",
       "17          2012              kentucky   679340.0  1087127.0\n",
       "18          2012             louisiana   808496.0  1152460.0\n",
       "19          2012                 maine   397754.0   290437.0\n",
       "20          2012              maryland  1527686.0   904970.0\n",
       "21          2012         massachusetts  1900575.0  1177370.0\n",
       "22          2012              michigan  2561911.0  2112673.0\n",
       "23          2012             minnesota  1547668.0  1321575.0\n",
       "24          2012           mississippi   528260.0   674302.0\n",
       "25          2012              missouri  1215031.0  1478961.0\n",
       "26          2012               montana   200489.0   264974.0\n",
       "27          2012              nebraska   289154.0   462972.0\n",
       "28          2012                nevada   528801.0   462422.0\n",
       "29          2012         new-hampshire   368529.0   327870.0\n",
       "30          2012            new-jersey  1960744.0  1383233.0\n",
       "31          2012            new-mexico   408312.0   331915.0\n",
       "32          2012              new-york  3875826.0  2226637.0\n",
       "33          2012        north-carolina  2178388.0  2275853.0\n",
       "34          2012          north-dakota   124490.0   187586.0\n",
       "35          2012                  ohio  2697260.0  2593779.0\n",
       "36          2012              oklahoma   442647.0   889372.0\n",
       "37          2012                oregon   937321.0   733743.0\n",
       "38          2012          pennsylvania  2907448.0  2619583.0\n",
       "39          2012          rhode-island   274342.0   155355.0\n",
       "40          2012        south-carolina   845756.0  1049507.0\n",
       "41          2012          south-dakota   144988.0   210541.0\n",
       "42          2012             tennessee   953043.0  1453097.0\n",
       "43          2012                 texas  3294440.0  4555799.0\n",
       "44          2012                  utah   229463.0   671747.0\n",
       "45          2012               vermont   199259.0    92700.0\n",
       "46          2012              virginia  1905528.0  1789618.0\n",
       "47          2012            washington  1620432.0  1210369.0\n",
       "48          2012         west-virginia   234925.0   412406.0\n",
       "49          2012             wisconsin  1613950.0  1408746.0\n",
       "50          2012               wyoming    68780.0   170265.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for 2016, we'll be using Politico again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def voter_html_to_data_2016(voter_html):\n",
    "    blue_votes = int(voter_html.find(class_='type-democrat').find(class_='results-popular').get_text().replace(',',''))\n",
    "    red_votes = int(voter_html.find(class_='type-republican').find(class_='results-popular').get_text().replace(',',''))\n",
    "    return [blue_votes, red_votes]\n",
    "\n",
    "def get_voter_data_2016():\n",
    "    # Set up our data frame\n",
    "    df = pd.DataFrame(columns=('election_year', 'state', 'dem_votes', 'rep_votes'))\n",
    "    \n",
    "    # Base url we'll be getting data from\n",
    "    base_url = 'http://www.politico.com/2016-election/results/map/president/'\n",
    "    \n",
    "    # Get state names for url endings\n",
    "    state_urls = sorted([state.lower().replace(' ', '-') for state in states])\n",
    "    \n",
    "    # This time, Alaska and D.C. aren't different!\n",
    "    num_states = 0\n",
    "    for state in state_urls:\n",
    "        # Get data from site\n",
    "        response = requests.get(base_url + state + '/')\n",
    "        election_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        data = election_soup.select('section.content-group.election-intro')[0].find('div', class_='overall')\n",
    "        header_data = ['2016', state]\n",
    "        voter_data = header_data + voter_html_to_data_2016(data)\n",
    "        df.loc[num_states] = voter_data\n",
    "        num_states += 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_2016 = get_voter_data_2016()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>election_year</th>\n",
       "      <th>state</th>\n",
       "      <th>dem_votes</th>\n",
       "      <th>rep_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>alabama</td>\n",
       "      <td>718084.0</td>\n",
       "      <td>1306925.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>alaska</td>\n",
       "      <td>93007.0</td>\n",
       "      <td>130415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>arizona</td>\n",
       "      <td>936250.0</td>\n",
       "      <td>1021154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>arkansas</td>\n",
       "      <td>378729.0</td>\n",
       "      <td>677904.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>california</td>\n",
       "      <td>7362490.0</td>\n",
       "      <td>3916209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>colorado</td>\n",
       "      <td>1208095.0</td>\n",
       "      <td>1136354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>884432.0</td>\n",
       "      <td>668266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>delaware</td>\n",
       "      <td>235581.0</td>\n",
       "      <td>185103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>district-of-columbia</td>\n",
       "      <td>260223.0</td>\n",
       "      <td>11553.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>florida</td>\n",
       "      <td>4485745.0</td>\n",
       "      <td>4605515.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016</td>\n",
       "      <td>georgia</td>\n",
       "      <td>1837300.0</td>\n",
       "      <td>2068623.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016</td>\n",
       "      <td>hawaii</td>\n",
       "      <td>251853.0</td>\n",
       "      <td>121648.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016</td>\n",
       "      <td>idaho</td>\n",
       "      <td>189677.0</td>\n",
       "      <td>407199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016</td>\n",
       "      <td>illinois</td>\n",
       "      <td>2977498.0</td>\n",
       "      <td>2118179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016</td>\n",
       "      <td>indiana</td>\n",
       "      <td>1031953.0</td>\n",
       "      <td>1556220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016</td>\n",
       "      <td>iowa</td>\n",
       "      <td>650790.0</td>\n",
       "      <td>798923.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016</td>\n",
       "      <td>kansas</td>\n",
       "      <td>414788.0</td>\n",
       "      <td>656009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2016</td>\n",
       "      <td>kentucky</td>\n",
       "      <td>628834.0</td>\n",
       "      <td>1202942.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016</td>\n",
       "      <td>louisiana</td>\n",
       "      <td>779535.0</td>\n",
       "      <td>1178004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2016</td>\n",
       "      <td>maine</td>\n",
       "      <td>354873.0</td>\n",
       "      <td>334838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2016</td>\n",
       "      <td>maryland</td>\n",
       "      <td>1497951.0</td>\n",
       "      <td>873646.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2016</td>\n",
       "      <td>massachusetts</td>\n",
       "      <td>1964768.0</td>\n",
       "      <td>1083069.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016</td>\n",
       "      <td>michigan</td>\n",
       "      <td>2268193.0</td>\n",
       "      <td>2279805.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2016</td>\n",
       "      <td>minnesota</td>\n",
       "      <td>1366676.0</td>\n",
       "      <td>1322891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2016</td>\n",
       "      <td>mississippi</td>\n",
       "      <td>462001.0</td>\n",
       "      <td>678457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016</td>\n",
       "      <td>missouri</td>\n",
       "      <td>1054889.0</td>\n",
       "      <td>1585753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016</td>\n",
       "      <td>montana</td>\n",
       "      <td>174521.0</td>\n",
       "      <td>274120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2016</td>\n",
       "      <td>nebraska</td>\n",
       "      <td>273858.0</td>\n",
       "      <td>485819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016</td>\n",
       "      <td>nevada</td>\n",
       "      <td>537753.0</td>\n",
       "      <td>511319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2016</td>\n",
       "      <td>new-hampshire</td>\n",
       "      <td>348521.0</td>\n",
       "      <td>345789.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2016</td>\n",
       "      <td>new-jersey</td>\n",
       "      <td>2021756.0</td>\n",
       "      <td>1535513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2016</td>\n",
       "      <td>new-mexico</td>\n",
       "      <td>380724.0</td>\n",
       "      <td>315875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2016</td>\n",
       "      <td>new-york</td>\n",
       "      <td>4143874.0</td>\n",
       "      <td>2640570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2016</td>\n",
       "      <td>north-carolina</td>\n",
       "      <td>2162074.0</td>\n",
       "      <td>2339603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2016</td>\n",
       "      <td>north-dakota</td>\n",
       "      <td>93526.0</td>\n",
       "      <td>216133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2016</td>\n",
       "      <td>ohio</td>\n",
       "      <td>2317001.0</td>\n",
       "      <td>2771984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2016</td>\n",
       "      <td>oklahoma</td>\n",
       "      <td>419788.0</td>\n",
       "      <td>947934.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2016</td>\n",
       "      <td>oregon</td>\n",
       "      <td>934631.0</td>\n",
       "      <td>742506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2016</td>\n",
       "      <td>pennsylvania</td>\n",
       "      <td>2844705.0</td>\n",
       "      <td>2912941.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2016</td>\n",
       "      <td>rhode-island</td>\n",
       "      <td>249902.0</td>\n",
       "      <td>179421.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2016</td>\n",
       "      <td>south-carolina</td>\n",
       "      <td>849469.0</td>\n",
       "      <td>1143611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2016</td>\n",
       "      <td>south-dakota</td>\n",
       "      <td>117442.0</td>\n",
       "      <td>227701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2016</td>\n",
       "      <td>tennessee</td>\n",
       "      <td>867110.0</td>\n",
       "      <td>1517402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2016</td>\n",
       "      <td>texas</td>\n",
       "      <td>3867816.0</td>\n",
       "      <td>4681590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2016</td>\n",
       "      <td>utah</td>\n",
       "      <td>274188.0</td>\n",
       "      <td>452086.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2016</td>\n",
       "      <td>vermont</td>\n",
       "      <td>178179.0</td>\n",
       "      <td>95053.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2016</td>\n",
       "      <td>virginia</td>\n",
       "      <td>1916845.0</td>\n",
       "      <td>1731156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2016</td>\n",
       "      <td>washington</td>\n",
       "      <td>1610524.0</td>\n",
       "      <td>1129120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2016</td>\n",
       "      <td>west-virginia</td>\n",
       "      <td>187457.0</td>\n",
       "      <td>486198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2016</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>1382210.0</td>\n",
       "      <td>1409467.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2016</td>\n",
       "      <td>wyoming</td>\n",
       "      <td>55949.0</td>\n",
       "      <td>174248.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   election_year                 state  dem_votes  rep_votes\n",
       "0           2016               alabama   718084.0  1306925.0\n",
       "1           2016                alaska    93007.0   130415.0\n",
       "2           2016               arizona   936250.0  1021154.0\n",
       "3           2016              arkansas   378729.0   677904.0\n",
       "4           2016            california  7362490.0  3916209.0\n",
       "5           2016              colorado  1208095.0  1136354.0\n",
       "6           2016           connecticut   884432.0   668266.0\n",
       "7           2016              delaware   235581.0   185103.0\n",
       "8           2016  district-of-columbia   260223.0    11553.0\n",
       "9           2016               florida  4485745.0  4605515.0\n",
       "10          2016               georgia  1837300.0  2068623.0\n",
       "11          2016                hawaii   251853.0   121648.0\n",
       "12          2016                 idaho   189677.0   407199.0\n",
       "13          2016              illinois  2977498.0  2118179.0\n",
       "14          2016               indiana  1031953.0  1556220.0\n",
       "15          2016                  iowa   650790.0   798923.0\n",
       "16          2016                kansas   414788.0   656009.0\n",
       "17          2016              kentucky   628834.0  1202942.0\n",
       "18          2016             louisiana   779535.0  1178004.0\n",
       "19          2016                 maine   354873.0   334838.0\n",
       "20          2016              maryland  1497951.0   873646.0\n",
       "21          2016         massachusetts  1964768.0  1083069.0\n",
       "22          2016              michigan  2268193.0  2279805.0\n",
       "23          2016             minnesota  1366676.0  1322891.0\n",
       "24          2016           mississippi   462001.0   678457.0\n",
       "25          2016              missouri  1054889.0  1585753.0\n",
       "26          2016               montana   174521.0   274120.0\n",
       "27          2016              nebraska   273858.0   485819.0\n",
       "28          2016                nevada   537753.0   511319.0\n",
       "29          2016         new-hampshire   348521.0   345789.0\n",
       "30          2016            new-jersey  2021756.0  1535513.0\n",
       "31          2016            new-mexico   380724.0   315875.0\n",
       "32          2016              new-york  4143874.0  2640570.0\n",
       "33          2016        north-carolina  2162074.0  2339603.0\n",
       "34          2016          north-dakota    93526.0   216133.0\n",
       "35          2016                  ohio  2317001.0  2771984.0\n",
       "36          2016              oklahoma   419788.0   947934.0\n",
       "37          2016                oregon   934631.0   742506.0\n",
       "38          2016          pennsylvania  2844705.0  2912941.0\n",
       "39          2016          rhode-island   249902.0   179421.0\n",
       "40          2016        south-carolina   849469.0  1143611.0\n",
       "41          2016          south-dakota   117442.0   227701.0\n",
       "42          2016             tennessee   867110.0  1517402.0\n",
       "43          2016                 texas  3867816.0  4681590.0\n",
       "44          2016                  utah   274188.0   452086.0\n",
       "45          2016               vermont   178179.0    95053.0\n",
       "46          2016              virginia  1916845.0  1731156.0\n",
       "47          2016            washington  1610524.0  1129120.0\n",
       "48          2016         west-virginia   187457.0   486198.0\n",
       "49          2016             wisconsin  1382210.0  1409467.0\n",
       "50          2016               wyoming    55949.0   174248.0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To aid in our analysis, we'll create a simple function to find the percent of the state that voted blue, given an election year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_percent_blue(state, year):\n",
    "    if year == 2008:\n",
    "        df = df_2008\n",
    "    elif year == 2012:\n",
    "        df = df_2012\n",
    "    else:\n",
    "        df = df_2016\n",
    "    df = df.set_index('state')\n",
    "    dem_votes = df.at[state,'dem_votes']\n",
    "    rep_votes = df.at[state, 'rep_votes']\n",
    "    return dem_votes / (dem_votes + rep_votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60713285679\n",
      "0.652778303597\n"
     ]
    }
   ],
   "source": [
    "print find_percent_blue('california', 2012)\n",
    "print find_percent_blue('california', 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We accumulate the dataframes for construction, manufacturing, and transportation and trade into one dataframe describing the total change in employment in these 3 blue collar industries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accumulate_blue_collar_industries(construction_df, manufacturing_df, transport_and_trade_df):\n",
    "    df = pd.Dataframe({\"state\": states})\n",
    "    df[2004] = construction_df[2004] + manufacturing_df[2004] + transport_and_trade_df[2004]\n",
    "    df[2008] = construction_df[2008] + manufacturing_df[2008] + transport_and_trade_df[2008]\n",
    "    df[2012] = construction_df[2012] + manufacturing_df[2012] + transport_and_trade_df[2012]\n",
    "    df[2016] = construction_df[2016] + manufacturing_df[2016] + transport_and_trade_df[2016]\n",
    "    return df\n",
    "\n",
    "blue_collar_df = accumulate_blue_collar_industries(construction_df, manufacturing_df, transport_and_trade_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make the dataframes that will be input into the SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_SVM_input(year, blue_collar_df, total_employment_df):\n",
    "    df = pd.DataFrame({\"state\": states, \n",
    "                       \"blue_collar_change_last_8_years\": (blue_collar_df[year] - blue_collar_df[year - 8]) / blue_collar_df[year - 8],\n",
    "                       \"total_employment_change_last_8_years\": (total_employment_df[year] - total_employment_df[year - 8]) / total_employment_df[year - 8]})\n",
    "    df[\"proportion_blue_4_years_ago\"] = df.apply(lambda row: find_percent_blue(row[\"state\"], year))\n",
    "    return df\n",
    "\n",
    "df_predict_2012 = create_SVM_input(2012, blue_collar_df, total_employment_df, df_2008)\n",
    "df_predict_2016 = create_SVM_input(2016, blue_collar_df, total_employment_df, df_2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we label each state with its result (1 for Democrat, 0 for Republican) in each of the last 3 presidential elections (2008, 2012, 2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    'Alabama': [0,0,0], 'Alaska': [0,0,0],\n",
    "    'Arizona': [0,0,0], 'Arkansas': [0,0,0],\n",
    "    'California': [1,1,1], 'Colorado': [1,1,1],\n",
    "    'Connecticut': [1,1,1], 'Delaware': [1,1,1],\n",
    "    'District Of Columbia': [1,1,1], 'Florida': [1,1,0],\n",
    "    'Georgia': [0,0,0], 'Hawaii': [1,1,1],\n",
    "    'Idaho': [0,0,0], 'Illinois': [1,1,1],\n",
    "    'Indiana': [1,0,0], 'Iowa': [1,1,0],\n",
    "    'Kansas': [0,0,0], 'Kentucky': [0,0,0],\n",
    "    'Louisiana': [0,0,0], 'Maine': [1,1,1],\n",
    "    'Maryland': [1,1,1],'Massachusetts': [1,1,1],\n",
    "    'Michigan': [1,1,0],'Minnesota': [1,1,1],\n",
    "    'Mississippi': [0,0,0], 'Missouri': [0,0,0],\n",
    "    'Montana': [0,0,0], 'Nebraska': [0,0,0],\n",
    "    'Nevada': [1,1,1], 'New Hampshire': [1,1,1],\n",
    "    'New Jersey': [1,1,1],'New Mexico': [1,1,1],\n",
    "    'New York': [1,1,1], 'North Carolina': [1,0,0],\n",
    "    'North Dakota': [0,0,0],'Ohio': [1,1,0],    \n",
    "    'Oklahoma': [0,0,0],'Oregon': [1,1,1],\n",
    "    'Pennsylvania': [1,1,0],'Rhode Island': [1,1,1],\n",
    "    'South Carolina': [0,0,0],'South Dakota': [0,0,0],\n",
    "    'Tennessee': [0,0,0],'Texas': [0,0,0],\n",
    "    'Utah': [0,0,0], 'Vermont': [1,1,1],\n",
    "    'Virginia': [1,1,1],'Washington': [1,1,1],\n",
    "    'West Virginia': [0,0,0], 'Wisconsin': [1,1,0],\n",
    "    'Wyoming': [0,0,0]\n",
    "}\n",
    "\n",
    "def provide_labels(year):\n",
    "    return np.array([v[(year - 2008) / 4] for k, v in results.iteritems()])\n",
    "    \n",
    "# df_predict_2012[\"alphabetical_state_results_2008\"] = provide_labels(2008)\n",
    "df_predict_2012[\"alphabetical_state_results_2012\"] = provide_labels(2012)\n",
    "df_predict_2016[\"alphabetical_state_results_2016\"] = provide_labels(2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've extracted all the necessary training data, we train an SVM on the features and labels of our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classifier for training examples, which are 2012 states and labels\n",
    "def learn_classifier(training_features, training_labels):\n",
    "    svc = sklearn.svm.SVC()\n",
    "    return svc.fit(training_features, training_labels)\n",
    "\n",
    "trained_svc = learn_classifier(df_predict_2012[\"blue_collar_change_last_8_years\", \n",
    "                                               \"total_employment_change_last_8_years\", \n",
    "                                               \"proportion_blue_4_years_ago\"], \n",
    "                               df_predict_2012[\"alphabetical_state_results_2012\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run our classifier on our testing set, the states in the 2016 election."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_classifier(svc, testing_features, testing_labels):\n",
    "    predicted_labels = svc.predict(testing_features)\n",
    "    return float(np.sum(predicted_labels == testing_labels)) / testing_features.shape[0]\n",
    "\n",
    "accuracy = eval_classifier(trained_svc, df_predict_2016[\"blue_collar_change_last_8_years\", \n",
    "                                                        \"total_employment_change_last_8_years\", \n",
    "                                                        \"proportion_blue_4_years_ago\"], \n",
    "                           df[\"alphabetical_state_results_2016\"])\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Scraping Labor Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* getting labor statistics from every state, by employment industry, from 2006 to 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json, string\n",
    "import requests, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def opand(x,y): \n",
    "    return x and y\n",
    "\n",
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "\n",
    "\n",
    "def nest(keys, d_keys, d):\n",
    "    assert (len(keys) == len(d_keys))\n",
    "    iters = string.join([\"for x%d in d['%s']\" % (i, d_key) for (i, d_key) in enumerate(d_keys)], sep=\" \")\n",
    "    args = string.join(['(\"' + keys[i] + '\", x' + str(i) + ')' for i in range(len(keys))], sep=\", \")\n",
    "    command = '[dict([' +  args +  ']) ' + iters + ']'\n",
    "    return eval(command)\n",
    "\n",
    "\n",
    "# 500 requests per day\n",
    "# 50 series per request\n",
    "# 20 years per request\n",
    "def request(series):\n",
    "    \"\"\"\n",
    "    brief:\n",
    "        - requests series in batches of 15, returns list of json_data, one for each request\n",
    "    args:\n",
    "        - series : list of bls series id's\n",
    "    \"\"\"\n",
    "    registrationKeys = [\"bc2b9775e9794f37a23c0f6b2a4659b1\", \"\", \"\"]\n",
    "    json_data = []\n",
    "    for i in tqdm.tqdm(range(0,len(series),50)):\n",
    "        headers = {'Content-type': 'application/json'}\n",
    "        data = json.dumps({\"seriesid\": series[i:i+50],\n",
    "                           \"startyear\":\"2004\", \n",
    "                           \"endyear\":\"2016\", \n",
    "                           \"registrationKey\":\"bc2b9775e9794f37a23c0f6b2a4659b1\"})\n",
    "        response = requests.post('http://api.bls.gov/publicAPI/v2/timeseries/data/', data=data, headers=headers)\n",
    "\n",
    "        json_data.append(json.loads(response.text))\n",
    "    return json_data #TODO: recombine json_data \n",
    "\n",
    "\n",
    "def format(config):\n",
    "    \"\"\"\n",
    "    brief:\n",
    "        - formats a request for data from the bls state and area employment, hours, and earnings database\n",
    "            if config['prefix'] == 'SM'\n",
    "        - formats a request for data from the bls local area unemployment statistics database\n",
    "            if config['prefix'] == 'SA'\n",
    "    args:\n",
    "        - config : {                                       # http://www.bls.gov/help/hlpforma.htm#SM\n",
    "                    'prefix' : 'SM',\n",
    "                    'seasonal_adjustment' : 'S' or 'U',\n",
    "                    'state_code' : '01' to '50', \n",
    "                    'area_code' : '00000' to '99999',\n",
    "                    'supersector' : '00' to '99', \n",
    "                    'industry' : '000000' to '999999',     \n",
    "                    'datatype' : '00' to '99'              \n",
    "                    }\n",
    "                or {\n",
    "                    'prefix' : 'LA',                       # http://www.bls.gov/help/hlpforma.htm#LA\n",
    "                    'seasonal_adjustment' : 'S' or 'U',\n",
    "                    'area_type' : 'ST' or 'MT', \n",
    "                    'state_code' : '01' to '50',\n",
    "                    'area_code' : '000000000' or 'YYYYYYYYYYY'\n",
    "                                   }\n",
    "                    'measure': '03' to '06'                }\n",
    "    \"\"\"\n",
    "    def valid(config):\n",
    "        if 'prefix' in config:\n",
    "            if 'seasonal_adjustment' in config and config['seasonal_adjustment'] in ['S', 'U']:\n",
    "                if config['prefix'] == 'SM':\n",
    "                    return ('state_code' in config and len(config['state_code']) == 2\n",
    "                        and 'area_code' in config and len(config['area_code']) == 5\n",
    "                        and 'supersector' in config and len(config['supersector']) == 2\n",
    "                        and 'industry' in config and len(config['industry']) == 6\n",
    "                        and 'datatype' in config and len(config['datatype']) == 2)\n",
    "\n",
    "                elif config['prefix'] == 'LA':\n",
    "                    return ('state_area_code' in config and len(config['state_area_code']) == 15\n",
    "                        and 'measure' in config and config['measure'] in ['03','04','05','06'])\n",
    "        return False\n",
    "    if valid(config):\n",
    "        # state and area employment, hours, and earnings\n",
    "        if config['prefix'] == 'SM':\n",
    "            # not using d.keys() here because keys must be in specific order\n",
    "            keys = ['prefix','seasonal_adjustment','state_code','area_code','supersector','industry','datatype']\n",
    "            series_id = string.join([config[key] for key in keys], sep=\"\")\n",
    "        # local area unemployment statistics\n",
    "        elif config['prefix'] == 'LA':\n",
    "            # not using d.keys() here because keys must be in specific order\n",
    "            keys = ['prefix', 'seasonal_adjustment', 'state_area_code', 'measure']\n",
    "            series_id = string.join([config[key] for key in keys], sep=\"\")\n",
    "        else:\n",
    "            raise Exception(\"KeyError: unsupported prefix\")\n",
    "        return series_id\n",
    "    else:\n",
    "        raise Exception(\"KeyError: invalid parameters\")\n",
    "\n",
    "\n",
    "def series(config):\n",
    "    \"\"\"\n",
    "    brief:\n",
    "        - provided a dictionary of bls series id parameters,\n",
    "          construct and request each possible series_id given parameters\n",
    "    args:\n",
    "        - config : {\n",
    "                    'prefix' : ['SM'],\n",
    "                    'seasonal_adjustments' : ['S' or 'U'],\n",
    "                    'state_codes' : [string],\n",
    "                    'area_codes' : [{string -> string}],\n",
    "                    'supersectors' : [string],\n",
    "                    'industries' : [string],\n",
    "                    'datatypes' : [string]\n",
    "                    }\n",
    "                or {\n",
    "                    'prefix' : ['LA'],\n",
    "                    'seasonal_adjustment' : ['S' or 'U'],\n",
    "                    'area_types' : ['ST' or 'MT'],\n",
    "                    'state_codes' : ['01' to '50']\n",
    "                    'area_codes' : [{'ST', 'xx' --> 'STxx00000000000', \n",
    "                                    'MT', 'xx' --> 'MTxxYYYYYYYYYYY'}]\n",
    "                    'measures': [string]\n",
    "                   }\n",
    "    \"\"\"\n",
    "    def valid(config):\n",
    "        if 'prefix' in config and config['prefix'] in [['SM'], ['LA']]:\n",
    "            if ('seasonal_adjustments' in config \n",
    "                and config['seasonal_adjustments'] in [['S'],['U'],['S','U'],['U','S']]):\n",
    "                if config['prefix'] == ['SM']:\n",
    "                    return ('state_codes' in config \n",
    "                            and reduce(opand, [0 < int(state_code) \n",
    "                                and int(state_code) <= 50 and len(state_code) == 2 \n",
    "                                    for state_code in config['state_codes']])\n",
    "                        and 'area_codes' in config \n",
    "                            and reduce(opand, [len(area_code) == 5 for area_code in config['area_codes']])\n",
    "                        and 'supersectors' in config \n",
    "                            and reduce(opand, [len(supersector) == 2 for supersector in config['supersectors']])\n",
    "                        and 'industries' in config\n",
    "                            and reduce(opand, [len(industry) == 6 for industry in config['industries']])\n",
    "                        and 'datatypes' in config)\n",
    "                elif config['prefix'] == ['LA']:\n",
    "                    return ('state_area_codes' in config and reduce(opand, [len(state_area_code) == 15\n",
    "                                                                            for state_area_code\n",
    "                                                                            in config['state_area_codes']])\n",
    "                        and 'measures' in config) \n",
    "        return False\n",
    "    if valid(config):\n",
    "        if config['prefix'] == ['SM']:\n",
    "            keys = ['prefix','seasonal_adjustment','state_code','area_code','supersector','industry','datatype']\n",
    "            param_keys = ['prefix','seasonal_adjustments','state_codes','area_codes',\n",
    "                          'supersectors','industries','datatypes']\n",
    "        elif config['prefix'] == ['LA']:\n",
    "            keys = ['prefix','seasonal_adjustment','state_area_code','measure']\n",
    "            param_keys = ['prefix','seasonal_adjustments','state_area_codes','measures']\n",
    "        else:\n",
    "            raise Exception(\"KeyError: unsupported prefix\")\n",
    "        return request([format(sid) for sid in nest(keys, param_keys, config)])\n",
    "    else:\n",
    "        raise Exception(\"KeyError: invalid parameters\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_codes = map(lambda i : str(i).zfill(2), range(1,51))\n",
    "\n",
    "with open('metro_codes.txt', 'r') as file:\n",
    "    metro_codes = [string.split(line, sep='\\t')[1] for line in string.split(file.read(), sep='\\n')]\n",
    "\n",
    "state_area_codes = {'ST' : dict(zip(state_codes, ['ST' + state_code + '00000000000' for state_code in state_codes])),\n",
    "                    'MT' : dict(zip(state_codes, metro_codes))\n",
    "                    }\n",
    "\n",
    "#print map(lambda mt : (len(mt), mt), metro_codes)\n",
    "\n",
    "stateIndustry_config = {'prefix' : ['SM'],\n",
    "                        'seasonal_adjustments' : ['S', 'U'],\n",
    "                        'state_codes' : state_codes,\n",
    "                        'area_codes' : ['00000'],\n",
    "                        'supersectors' : ['00','05','06','07','08','10','15','20','30','31','32',\n",
    "                                          '40','41','42','43','50','55','60','65','70','80','90'],\n",
    "                        'industries' : ['000000'],\n",
    "                        'datatypes' : ['01', '02', '03', '04'] # industry employees in thousands,\n",
    "                        }                                      # average weekly hours of all employees,\n",
    "                                                               # average hourly earnings of all employees,\n",
    "                                                               # average overtime hours of all employees\n",
    "state_config = {'prefix' : ['LA'],\n",
    "                'seasonal_adjustments' : ['S', 'U'],\n",
    "                'state_area_codes' : [state_area_codes['ST'][state_code] for state_code in state_codes],\n",
    "                'measures' : ['03', '04', '05', '06'] # unemployment_rate, unemployment, employment, labor_force\n",
    "                }\n",
    "\n",
    "stateMetro_config = {'prefix' : ['LA'],\n",
    "                     'seasonal_adjustments' : ['S', 'U'],\n",
    "                     'state_area_codes' : [state_area_codes['MT'][state_code] for state_code in state_codes],\n",
    "                     'measures' : ['03', '04', '05', '06'] # unemployment_rate, unemployment, employment, labor_force\n",
    "                     }\n",
    "\n",
    "stateIndustry_json = series(stateIndustry_config)\n",
    "state_json = series(state_config)\n",
    "stateMetro_json = series(stateMetro_config)\n",
    "\n",
    "#print stateIndustry_json\n",
    "# print state_json\n",
    "# print stateMetro_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import prettytable\n",
    "\n",
    "def saveTextFile(json_data):\n",
    "    for series in json_data['Results']['series']:\n",
    "        x=prettytable.PrettyTable([\"series id\",\"year\",\"period\",\"value\",\"footnotes\"])\n",
    "        seriesId = series['seriesID']\n",
    "        for item in series['data']:\n",
    "            year = item['year']\n",
    "            period = item['period']\n",
    "            value = item['value']\n",
    "            footnotes=\"\"\n",
    "            for footnote in item['footnotes']:\n",
    "                if footnote:\n",
    "                    footnotes = footnotes + footnote['text'] + ','\n",
    "            if 'M01' <= period <= 'M12':\n",
    "                x.add_row([seriesId,year,period,value,footnotes[0:-1]])\n",
    "    output = open('data/' + seriesId + '.txt','w')\n",
    "    output.write (x.get_string())\n",
    "    output.close()\n",
    "\n",
    "# saveTextFile(stateIndustry_json)\n",
    "# saveTextFile(state_json)\n",
    "# saveTextFile(stateMetro_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: pandas dataframes...\n",
    "\n",
    "# [Jake]: I have a local implementation for converting to pandas dataframes, but its buggy, \n",
    "#         and I can't test it as I exceeded BLS's 500 daily query limit\n",
    "\n",
    "# can one of you add another registrationKey (in the requests function, in the first BLS cell?)\n",
    "# http://data.bls.gov/registrationEngine/"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
