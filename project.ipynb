{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## America's Working Class and How It Helped Swing the 2016 Election"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many pundits have argued that this past election was decided by America's working class. It has always been the case that jobs and the economy play a pivotal role in influencing the voting decisions of many Americans. With the Great Recession of 2008-2011, and an increasing shift towards a globalized economy, traditionally blue-collar industries such as construction, manufacturing, and transportation and trade felt the brunt of those effects through the loss of jobs. \n",
    "\n",
    "We hypothesize in this project that the people most affected by these changes - America's working class - responded to these changes with their votes, and may correlate with whether a state went red or blue in 2016. While obviously it's hard to definitively pin down a cause just based on how people voted, we want to compare labor department data about umeployment in certain sectors and voting data from certain states to see if we can find a trend or come to any interesting conclusions.\n",
    "\n",
    "For our project, we look towards a number of sources to aid in our analysis. First, on the labor statistics front, we looked towards the [Bureau of Labor Statistics](http://www.bls.gov/bls/proghome.htm) and, specifically, the [Bureau of Labor Statistics Public Data API](http://www.bls.gov/developers/api_signature_v2.htm) to collect data on unemployment over the industries most impacted by the recession, and break down this data by state. We will combine this feature with the recovery rate of a given state by 2016. Second, for election data, we turn towards major news sources like [Politico](http://www.politico.com/) and the [New York Times](http://www.nytimes.com) to collect voter numbers from each state during the 2008, 2012, and 2016 elections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Election"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though both Politico and the New York Times, as many news sources do, ultimately draw their data from the Associated Press, API keys for AP aren't free, so we'll have to take a slightly more indirect approach by scraping the news pages themselves for the data instead of getting it directly from AP. Unfortunately, due to formatting changes over the years, it's a little more difficult than we'd like it to be to fetch voter data from the 2008, 2012, and 2016 elections with one script. However, it's not too hard to write scripts for each of those elections individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "# pd.options.display.max_seq_items = 2000\n",
    "# pd.set_option('display.height', 1000)\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import sklearn\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "years = ['2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016']\n",
    "\n",
    "\n",
    "# List of states and D.C.\n",
    "states = [\n",
    "    'Alabama','Alaska','Arizona','Arkansas','California','Colorado',\n",
    "    'Connecticut','Delaware','District Of Columbia','Florida','Georgia','Hawaii','Idaho', \n",
    "    'Illinois','Indiana','Iowa','Kansas','Kentucky','Louisiana',\n",
    "    'Maine','Maryland','Massachusetts','Michigan','Minnesota',\n",
    "    'Mississippi', 'Missouri','Montana','Nebraska','Nevada',\n",
    "    'New Hampshire','New Jersey','New Mexico','New York',\n",
    "    'North Carolina','North Dakota','Ohio',    \n",
    "    'Oklahoma','Oregon','Pennsylvania','Rhode Island',\n",
    "    'South Carolina','South Dakota','Tennessee','Texas','Utah',\n",
    "    'Vermont','Virginia','Washington','West Virginia',\n",
    "    'Wisconsin','Wyoming'\n",
    "]\n",
    "\n",
    "state_codes = {\n",
    "    'Alabama' : '01',\n",
    "    'Alaska' : '02',\n",
    "    'Arizona' : '04',\n",
    "    'Arkansas' : '05',\n",
    "    'California' : '06',\n",
    "    'Colorado' : '08',\n",
    "    'Connecticut' : '09',\n",
    "    'Delaware' : '10',\n",
    "    'District Of Columbia' : '11',\n",
    "    'Florida' : '12',\n",
    "    'Georgia' : '13',\n",
    "    'Hawaii' : '15',\n",
    "    'Idaho' : '16', \n",
    "    'Illinois' : '17',\n",
    "    'Indiana' : '18',\n",
    "    'Iowa' : '19',\n",
    "    'Kansas' : '20',\n",
    "    'Kentucky' : '21',\n",
    "    'Louisiana' : '22',\n",
    "    'Maine' : '23',\n",
    "    'Maryland' : '24',\n",
    "    'Massachusetts' : '25',\n",
    "    'Michigan' : '26',\n",
    "    'Minnesota' : '27',\n",
    "    'Mississippi' : '28',\n",
    "    'Missouri' : '29',\n",
    "    'Montana' : '30',\n",
    "    'Nebraska' : '31',\n",
    "    'Nevada' : '32',\n",
    "    'New Hampshire' : '33',\n",
    "    'New Jersey' : '34',\n",
    "    'New Mexico' : '35',\n",
    "    'New York' : '36',\n",
    "    'North Carolina' : '37',\n",
    "    'North Dakota' : '38',\n",
    "    'Ohio' : '39',    \n",
    "    'Oklahoma' : '40',\n",
    "    'Oregon' : '41',\n",
    "    'Pennsylvania' : '42',\n",
    "    'Rhode Island' : '44',\n",
    "    'South Carolina' : '45',\n",
    "    'South Dakota' : '46',\n",
    "    'Tennessee' : '47',\n",
    "    'Texas' : '48',\n",
    "    'Utah' : '49',\n",
    "    'Vermont' : '50',\n",
    "    'Virginia' : '51',\n",
    "    'Washington' : '53',\n",
    "    'West Virginia' : '54',\n",
    "    'Wisconsin' : '55',\n",
    "    'Wyoming' : '56'\n",
    "    }\n",
    "\n",
    "industries = ['information', 'finance', 'construction', 'manufacturing', 'transport_and_trade', 'all']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll be collecting 2008 data from the New York Times page on the election. In terms of formatting, we're hoping to get mainly the state and the number of votes for the Democratic and Republican party candidates (we'll be ignoring third-parties in this analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Converts data taken from the table in the html\n",
    "    Input: a table row of voting data, in html\n",
    "    Output: a list of data in a more desirable format\n",
    "'''\n",
    "def voter_html_to_data_2008(voter_html):\n",
    "    data = [datum.get_text().strip() for datum in voter_html.find_all('td')]\n",
    "    blue_votes = int(data[2][:-5].replace(',',''))\n",
    "    red_votes = int(data[4][:-5].replace(',',''))\n",
    "    return [blue_votes, red_votes]\n",
    "\n",
    "def get_voter_data_2008():\n",
    "    # Set up our data frame\n",
    "    df = pd.DataFrame(columns=('election_year', 'state', 'dem_votes', 'rep_votes'))\n",
    "    \n",
    "    # Base url we'll be getting data from \n",
    "    base_url = 'http://elections.nytimes.com/2008/results/states/president/'\n",
    "    \n",
    "    # Get state names for url endings\n",
    "    state_urls = sorted([state.lower().replace(' ', '-') for state in states])\n",
    "\n",
    "    # Iterate through the states (except for Alaska and D.C.)\n",
    "    num_states = 0\n",
    "    for state in state_urls:\n",
    "        if state != 'alaska' and state != 'district-of-columbia':\n",
    "            # Get data from the site\n",
    "            response = requests.get(base_url + state + '.html')\n",
    "            election_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Data for all states except for Alaska and D.C.\n",
    "            data_rows = election_soup.find(id='winners-by-county-table').tbody.find_all('tr')\n",
    "            \n",
    "            # Data that every row will have (election year and state)\n",
    "            header_data = ['2008', state]\n",
    "            state_vote_lists = [voter_html_to_data_2008(row) for row in data_rows]\n",
    "            state_vote_counts = [sum([vote[0] for vote in state_vote_lists]), sum([vote[1] for vote in state_vote_lists])]\n",
    "            voter_data = header_data + state_vote_counts\n",
    "            df.loc[num_states] = voter_data\n",
    "            num_states += 1\n",
    "    \n",
    "    # Since Alaska and D.C. don't have counties, we process them slightly differently\n",
    "    # First, Alaska\n",
    "    alaska_html = requests.get('http://elections.nytimes.com/2008/results/states/alaska.html')\n",
    "    alaska_election_soup = BeautifulSoup(alaska_html.text, 'html.parser')\n",
    "    \n",
    "    alaska_obama = alaska_election_soup.find(id='presidential-results-table').tbody.find_all('tr')[:2][1].find_all('td')\n",
    "    alaska_mccain = alaska_election_soup.find(id='presidential-results-table').tbody.find_all('tr')[:2][0].find_all('td')\n",
    "    alaska_blue_votes = int(alaska_obama[1].get_text().strip().replace(',',''))\n",
    "    alaska_red_votes = int(alaska_mccain[2].get_text().strip().replace(',',''))\n",
    "    alaska_data = ['2008', 'alaska', alaska_blue_votes, alaska_red_votes]\n",
    "    df.loc[num_states] = alaska_data\n",
    "    num_states += 1\n",
    "    \n",
    "    # Finally, D.C.\n",
    "    dc_html = requests.get('http://elections.nytimes.com/2008/results/states/district-of-columbia.html')\n",
    "    dc_election_soup = BeautifulSoup(dc_html.text, 'html.parser')\n",
    "\n",
    "    dc_obama = dc_election_soup.find(id='presidential-results-table').tbody.find_all('tr')[:2][0].find_all('td')\n",
    "    dc_mccain = dc_election_soup.find(id='presidential-results-table').tbody.find_all('tr')[:2][1].find_all('td')\n",
    "    dc_blue_votes = int(dc_obama[2].get_text().strip().replace(',',''))\n",
    "    dc_red_votes = int(dc_mccain[1].get_text().strip().replace(',',''))\n",
    "    dc_data = ['2008', 'district-of-columbia', dc_blue_votes, dc_red_votes]\n",
    "    df.loc[num_states] = dc_data\n",
    "    num_states += 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_2008 = get_voter_data_2008()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>election_year</th>\n",
       "      <th>state</th>\n",
       "      <th>dem_votes</th>\n",
       "      <th>rep_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>alabama</td>\n",
       "      <td>811764.0</td>\n",
       "      <td>1264879.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>arizona</td>\n",
       "      <td>948648.0</td>\n",
       "      <td>1132560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>arkansas</td>\n",
       "      <td>418049.0</td>\n",
       "      <td>632672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>california</td>\n",
       "      <td>7441458.0</td>\n",
       "      <td>4554643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>colorado</td>\n",
       "      <td>1216793.0</td>\n",
       "      <td>1020135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>994320.0</td>\n",
       "      <td>627688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2008</td>\n",
       "      <td>delaware</td>\n",
       "      <td>255394.0</td>\n",
       "      <td>152356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008</td>\n",
       "      <td>florida</td>\n",
       "      <td>4143957.0</td>\n",
       "      <td>3939380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008</td>\n",
       "      <td>georgia</td>\n",
       "      <td>1843452.0</td>\n",
       "      <td>2048244.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2008</td>\n",
       "      <td>hawaii</td>\n",
       "      <td>324918.0</td>\n",
       "      <td>120309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2008</td>\n",
       "      <td>idaho</td>\n",
       "      <td>235219.0</td>\n",
       "      <td>400989.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2008</td>\n",
       "      <td>illinois</td>\n",
       "      <td>3319237.0</td>\n",
       "      <td>1981158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2008</td>\n",
       "      <td>indiana</td>\n",
       "      <td>1367264.0</td>\n",
       "      <td>1341101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2008</td>\n",
       "      <td>iowa</td>\n",
       "      <td>818240.0</td>\n",
       "      <td>677508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2008</td>\n",
       "      <td>kansas</td>\n",
       "      <td>499979.0</td>\n",
       "      <td>685541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2008</td>\n",
       "      <td>kentucky</td>\n",
       "      <td>746510.0</td>\n",
       "      <td>1043264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2008</td>\n",
       "      <td>louisiana</td>\n",
       "      <td>780981.0</td>\n",
       "      <td>1147603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2008</td>\n",
       "      <td>maine</td>\n",
       "      <td>421481.0</td>\n",
       "      <td>296192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2008</td>\n",
       "      <td>maryland</td>\n",
       "      <td>1612692.0</td>\n",
       "      <td>956663.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2008</td>\n",
       "      <td>massachusetts</td>\n",
       "      <td>1891083.0</td>\n",
       "      <td>1104284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2008</td>\n",
       "      <td>michigan</td>\n",
       "      <td>2867680.0</td>\n",
       "      <td>2044405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2008</td>\n",
       "      <td>minnesota</td>\n",
       "      <td>1573323.0</td>\n",
       "      <td>1275400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2008</td>\n",
       "      <td>mississippi</td>\n",
       "      <td>520864.0</td>\n",
       "      <td>687266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2008</td>\n",
       "      <td>missouri</td>\n",
       "      <td>1442180.0</td>\n",
       "      <td>1445812.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2008</td>\n",
       "      <td>montana</td>\n",
       "      <td>229725.0</td>\n",
       "      <td>241816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2008</td>\n",
       "      <td>nebraska</td>\n",
       "      <td>329132.0</td>\n",
       "      <td>448801.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2008</td>\n",
       "      <td>nevada</td>\n",
       "      <td>531884.0</td>\n",
       "      <td>411988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2008</td>\n",
       "      <td>new-hampshire</td>\n",
       "      <td>384591.0</td>\n",
       "      <td>316937.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2008</td>\n",
       "      <td>new-jersey</td>\n",
       "      <td>2085051.0</td>\n",
       "      <td>1545495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2008</td>\n",
       "      <td>new-mexico</td>\n",
       "      <td>458754.0</td>\n",
       "      <td>340857.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2008</td>\n",
       "      <td>new-york</td>\n",
       "      <td>4363386.0</td>\n",
       "      <td>2576360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2008</td>\n",
       "      <td>north-carolina</td>\n",
       "      <td>2123390.0</td>\n",
       "      <td>2109698.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2008</td>\n",
       "      <td>north-dakota</td>\n",
       "      <td>141113.0</td>\n",
       "      <td>168523.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2008</td>\n",
       "      <td>ohio</td>\n",
       "      <td>2708685.0</td>\n",
       "      <td>2501855.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2008</td>\n",
       "      <td>oklahoma</td>\n",
       "      <td>502294.0</td>\n",
       "      <td>959745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2008</td>\n",
       "      <td>oregon</td>\n",
       "      <td>978605.0</td>\n",
       "      <td>699673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2008</td>\n",
       "      <td>pennsylvania</td>\n",
       "      <td>3192316.0</td>\n",
       "      <td>2586496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2008</td>\n",
       "      <td>rhode-island</td>\n",
       "      <td>275488.0</td>\n",
       "      <td>152502.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2008</td>\n",
       "      <td>south-carolina</td>\n",
       "      <td>850121.0</td>\n",
       "      <td>1018756.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2008</td>\n",
       "      <td>south-dakota</td>\n",
       "      <td>170886.0</td>\n",
       "      <td>203019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2008</td>\n",
       "      <td>tennessee</td>\n",
       "      <td>1081074.0</td>\n",
       "      <td>1470160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2008</td>\n",
       "      <td>texas</td>\n",
       "      <td>3521164.0</td>\n",
       "      <td>4467748.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2008</td>\n",
       "      <td>utah</td>\n",
       "      <td>317063.0</td>\n",
       "      <td>568610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2008</td>\n",
       "      <td>vermont</td>\n",
       "      <td>219105.0</td>\n",
       "      <td>98791.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2008</td>\n",
       "      <td>virginia</td>\n",
       "      <td>1958370.0</td>\n",
       "      <td>1726053.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2008</td>\n",
       "      <td>washington</td>\n",
       "      <td>1547632.0</td>\n",
       "      <td>1097176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2008</td>\n",
       "      <td>west-virginia</td>\n",
       "      <td>301438.0</td>\n",
       "      <td>394278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2008</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>1670474.0</td>\n",
       "      <td>1258181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2008</td>\n",
       "      <td>wyoming</td>\n",
       "      <td>80496.0</td>\n",
       "      <td>160639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2008</td>\n",
       "      <td>alaska</td>\n",
       "      <td>122485.0</td>\n",
       "      <td>192631.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2008</td>\n",
       "      <td>district-of-columbia</td>\n",
       "      <td>210403.0</td>\n",
       "      <td>14821.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   election_year                 state  dem_votes  rep_votes\n",
       "0           2008               alabama   811764.0  1264879.0\n",
       "1           2008               arizona   948648.0  1132560.0\n",
       "2           2008              arkansas   418049.0   632672.0\n",
       "3           2008            california  7441458.0  4554643.0\n",
       "4           2008              colorado  1216793.0  1020135.0\n",
       "5           2008           connecticut   994320.0   627688.0\n",
       "6           2008              delaware   255394.0   152356.0\n",
       "7           2008               florida  4143957.0  3939380.0\n",
       "8           2008               georgia  1843452.0  2048244.0\n",
       "9           2008                hawaii   324918.0   120309.0\n",
       "10          2008                 idaho   235219.0   400989.0\n",
       "11          2008              illinois  3319237.0  1981158.0\n",
       "12          2008               indiana  1367264.0  1341101.0\n",
       "13          2008                  iowa   818240.0   677508.0\n",
       "14          2008                kansas   499979.0   685541.0\n",
       "15          2008              kentucky   746510.0  1043264.0\n",
       "16          2008             louisiana   780981.0  1147603.0\n",
       "17          2008                 maine   421481.0   296192.0\n",
       "18          2008              maryland  1612692.0   956663.0\n",
       "19          2008         massachusetts  1891083.0  1104284.0\n",
       "20          2008              michigan  2867680.0  2044405.0\n",
       "21          2008             minnesota  1573323.0  1275400.0\n",
       "22          2008           mississippi   520864.0   687266.0\n",
       "23          2008              missouri  1442180.0  1445812.0\n",
       "24          2008               montana   229725.0   241816.0\n",
       "25          2008              nebraska   329132.0   448801.0\n",
       "26          2008                nevada   531884.0   411988.0\n",
       "27          2008         new-hampshire   384591.0   316937.0\n",
       "28          2008            new-jersey  2085051.0  1545495.0\n",
       "29          2008            new-mexico   458754.0   340857.0\n",
       "30          2008              new-york  4363386.0  2576360.0\n",
       "31          2008        north-carolina  2123390.0  2109698.0\n",
       "32          2008          north-dakota   141113.0   168523.0\n",
       "33          2008                  ohio  2708685.0  2501855.0\n",
       "34          2008              oklahoma   502294.0   959745.0\n",
       "35          2008                oregon   978605.0   699673.0\n",
       "36          2008          pennsylvania  3192316.0  2586496.0\n",
       "37          2008          rhode-island   275488.0   152502.0\n",
       "38          2008        south-carolina   850121.0  1018756.0\n",
       "39          2008          south-dakota   170886.0   203019.0\n",
       "40          2008             tennessee  1081074.0  1470160.0\n",
       "41          2008                 texas  3521164.0  4467748.0\n",
       "42          2008                  utah   317063.0   568610.0\n",
       "43          2008               vermont   219105.0    98791.0\n",
       "44          2008              virginia  1958370.0  1726053.0\n",
       "45          2008            washington  1547632.0  1097176.0\n",
       "46          2008         west-virginia   301438.0   394278.0\n",
       "47          2008             wisconsin  1670474.0  1258181.0\n",
       "48          2008               wyoming    80496.0   160639.0\n",
       "49          2008                alaska   122485.0   192631.0\n",
       "50          2008  district-of-columbia   210403.0    14821.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 2012, we'll switch to Politico, since the website formatting is slightly easier to parse than the interactive graphics on the New York Times site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_voter_data_2012():\n",
    "    # Set up our data frame\n",
    "    df = pd.DataFrame(columns=('election_year', 'state', 'dem_votes', 'rep_votes'))\n",
    "    \n",
    "    # Base url we'll be getting data from\n",
    "    base_url = 'http://www.politico.com/2012-election/results/president/'\n",
    "    \n",
    "    # Get state names for url endings\n",
    "    state_urls = sorted([state.lower().replace(' ', '-') for state in states])\n",
    "    \n",
    "    # Once again, Alaska and D.C. are slightly different\n",
    "    num_states = 0\n",
    "    for state in state_urls:\n",
    "        # Get data from site\n",
    "        try:\n",
    "            response = requests.get(base_url + state + '/')\n",
    "        except ConnectionError:\n",
    "            time.sleep(2)\n",
    "            response = requests.get(base_url + state + '/')\n",
    "        election_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        header_data = ['2012', state]\n",
    "        data = election_soup.find('div', class_='state-results-macro').table.tbody\n",
    "        blue_votes = int(data.find(class_='party-democrat').find(class_='results-popular').get_text().strip().replace(',',''))\n",
    "        red_votes = int(data.find(class_='party-republican').find(class_='results-popular').get_text().strip().replace(',',''))\n",
    "        voter_data = header_data + [blue_votes, red_votes]\n",
    "        df.loc[num_states] = voter_data\n",
    "        num_states += 1\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_2012 = get_voter_data_2012()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>election_year</th>\n",
       "      <th>state</th>\n",
       "      <th>dem_votes</th>\n",
       "      <th>rep_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>alabama</td>\n",
       "      <td>793620.0</td>\n",
       "      <td>1252453.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>alaska</td>\n",
       "      <td>102138.0</td>\n",
       "      <td>136848.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>arizona</td>\n",
       "      <td>930669.0</td>\n",
       "      <td>1143051.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "      <td>arkansas</td>\n",
       "      <td>389699.0</td>\n",
       "      <td>638467.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>california</td>\n",
       "      <td>6493924.0</td>\n",
       "      <td>4202127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>colorado</td>\n",
       "      <td>1238490.0</td>\n",
       "      <td>1125391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>912531.0</td>\n",
       "      <td>631432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012</td>\n",
       "      <td>delaware</td>\n",
       "      <td>242547.0</td>\n",
       "      <td>165476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012</td>\n",
       "      <td>district-of-columbia</td>\n",
       "      <td>222332.0</td>\n",
       "      <td>17337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012</td>\n",
       "      <td>florida</td>\n",
       "      <td>4235270.0</td>\n",
       "      <td>4162081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2012</td>\n",
       "      <td>georgia</td>\n",
       "      <td>1761761.0</td>\n",
       "      <td>2070221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012</td>\n",
       "      <td>hawaii</td>\n",
       "      <td>303090.0</td>\n",
       "      <td>119494.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012</td>\n",
       "      <td>idaho</td>\n",
       "      <td>212560.0</td>\n",
       "      <td>420750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2012</td>\n",
       "      <td>illinois</td>\n",
       "      <td>2916811.0</td>\n",
       "      <td>2090116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2012</td>\n",
       "      <td>indiana</td>\n",
       "      <td>1140425.0</td>\n",
       "      <td>1412620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2012</td>\n",
       "      <td>iowa</td>\n",
       "      <td>816429.0</td>\n",
       "      <td>727928.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2012</td>\n",
       "      <td>kansas</td>\n",
       "      <td>427918.0</td>\n",
       "      <td>678719.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2012</td>\n",
       "      <td>kentucky</td>\n",
       "      <td>679340.0</td>\n",
       "      <td>1087127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2012</td>\n",
       "      <td>louisiana</td>\n",
       "      <td>808496.0</td>\n",
       "      <td>1152460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2012</td>\n",
       "      <td>maine</td>\n",
       "      <td>397754.0</td>\n",
       "      <td>290437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2012</td>\n",
       "      <td>maryland</td>\n",
       "      <td>1527686.0</td>\n",
       "      <td>904970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2012</td>\n",
       "      <td>massachusetts</td>\n",
       "      <td>1900575.0</td>\n",
       "      <td>1177370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2012</td>\n",
       "      <td>michigan</td>\n",
       "      <td>2561911.0</td>\n",
       "      <td>2112673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2012</td>\n",
       "      <td>minnesota</td>\n",
       "      <td>1547668.0</td>\n",
       "      <td>1321575.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2012</td>\n",
       "      <td>mississippi</td>\n",
       "      <td>528260.0</td>\n",
       "      <td>674302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2012</td>\n",
       "      <td>missouri</td>\n",
       "      <td>1215031.0</td>\n",
       "      <td>1478961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2012</td>\n",
       "      <td>montana</td>\n",
       "      <td>200489.0</td>\n",
       "      <td>264974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2012</td>\n",
       "      <td>nebraska</td>\n",
       "      <td>289154.0</td>\n",
       "      <td>462972.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2012</td>\n",
       "      <td>nevada</td>\n",
       "      <td>528801.0</td>\n",
       "      <td>462422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2012</td>\n",
       "      <td>new-hampshire</td>\n",
       "      <td>368529.0</td>\n",
       "      <td>327870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2012</td>\n",
       "      <td>new-jersey</td>\n",
       "      <td>1960744.0</td>\n",
       "      <td>1383233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2012</td>\n",
       "      <td>new-mexico</td>\n",
       "      <td>408312.0</td>\n",
       "      <td>331915.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2012</td>\n",
       "      <td>new-york</td>\n",
       "      <td>3875826.0</td>\n",
       "      <td>2226637.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2012</td>\n",
       "      <td>north-carolina</td>\n",
       "      <td>2178388.0</td>\n",
       "      <td>2275853.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2012</td>\n",
       "      <td>north-dakota</td>\n",
       "      <td>124490.0</td>\n",
       "      <td>187586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2012</td>\n",
       "      <td>ohio</td>\n",
       "      <td>2697260.0</td>\n",
       "      <td>2593779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2012</td>\n",
       "      <td>oklahoma</td>\n",
       "      <td>442647.0</td>\n",
       "      <td>889372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2012</td>\n",
       "      <td>oregon</td>\n",
       "      <td>937321.0</td>\n",
       "      <td>733743.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2012</td>\n",
       "      <td>pennsylvania</td>\n",
       "      <td>2907448.0</td>\n",
       "      <td>2619583.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2012</td>\n",
       "      <td>rhode-island</td>\n",
       "      <td>274342.0</td>\n",
       "      <td>155355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2012</td>\n",
       "      <td>south-carolina</td>\n",
       "      <td>845756.0</td>\n",
       "      <td>1049507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2012</td>\n",
       "      <td>south-dakota</td>\n",
       "      <td>144988.0</td>\n",
       "      <td>210541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2012</td>\n",
       "      <td>tennessee</td>\n",
       "      <td>953043.0</td>\n",
       "      <td>1453097.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2012</td>\n",
       "      <td>texas</td>\n",
       "      <td>3294440.0</td>\n",
       "      <td>4555799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2012</td>\n",
       "      <td>utah</td>\n",
       "      <td>229463.0</td>\n",
       "      <td>671747.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2012</td>\n",
       "      <td>vermont</td>\n",
       "      <td>199259.0</td>\n",
       "      <td>92700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2012</td>\n",
       "      <td>virginia</td>\n",
       "      <td>1905528.0</td>\n",
       "      <td>1789618.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2012</td>\n",
       "      <td>washington</td>\n",
       "      <td>1620432.0</td>\n",
       "      <td>1210369.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2012</td>\n",
       "      <td>west-virginia</td>\n",
       "      <td>234925.0</td>\n",
       "      <td>412406.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2012</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>1613950.0</td>\n",
       "      <td>1408746.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2012</td>\n",
       "      <td>wyoming</td>\n",
       "      <td>68780.0</td>\n",
       "      <td>170265.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   election_year                 state  dem_votes  rep_votes\n",
       "0           2012               alabama   793620.0  1252453.0\n",
       "1           2012                alaska   102138.0   136848.0\n",
       "2           2012               arizona   930669.0  1143051.0\n",
       "3           2012              arkansas   389699.0   638467.0\n",
       "4           2012            california  6493924.0  4202127.0\n",
       "5           2012              colorado  1238490.0  1125391.0\n",
       "6           2012           connecticut   912531.0   631432.0\n",
       "7           2012              delaware   242547.0   165476.0\n",
       "8           2012  district-of-columbia   222332.0    17337.0\n",
       "9           2012               florida  4235270.0  4162081.0\n",
       "10          2012               georgia  1761761.0  2070221.0\n",
       "11          2012                hawaii   303090.0   119494.0\n",
       "12          2012                 idaho   212560.0   420750.0\n",
       "13          2012              illinois  2916811.0  2090116.0\n",
       "14          2012               indiana  1140425.0  1412620.0\n",
       "15          2012                  iowa   816429.0   727928.0\n",
       "16          2012                kansas   427918.0   678719.0\n",
       "17          2012              kentucky   679340.0  1087127.0\n",
       "18          2012             louisiana   808496.0  1152460.0\n",
       "19          2012                 maine   397754.0   290437.0\n",
       "20          2012              maryland  1527686.0   904970.0\n",
       "21          2012         massachusetts  1900575.0  1177370.0\n",
       "22          2012              michigan  2561911.0  2112673.0\n",
       "23          2012             minnesota  1547668.0  1321575.0\n",
       "24          2012           mississippi   528260.0   674302.0\n",
       "25          2012              missouri  1215031.0  1478961.0\n",
       "26          2012               montana   200489.0   264974.0\n",
       "27          2012              nebraska   289154.0   462972.0\n",
       "28          2012                nevada   528801.0   462422.0\n",
       "29          2012         new-hampshire   368529.0   327870.0\n",
       "30          2012            new-jersey  1960744.0  1383233.0\n",
       "31          2012            new-mexico   408312.0   331915.0\n",
       "32          2012              new-york  3875826.0  2226637.0\n",
       "33          2012        north-carolina  2178388.0  2275853.0\n",
       "34          2012          north-dakota   124490.0   187586.0\n",
       "35          2012                  ohio  2697260.0  2593779.0\n",
       "36          2012              oklahoma   442647.0   889372.0\n",
       "37          2012                oregon   937321.0   733743.0\n",
       "38          2012          pennsylvania  2907448.0  2619583.0\n",
       "39          2012          rhode-island   274342.0   155355.0\n",
       "40          2012        south-carolina   845756.0  1049507.0\n",
       "41          2012          south-dakota   144988.0   210541.0\n",
       "42          2012             tennessee   953043.0  1453097.0\n",
       "43          2012                 texas  3294440.0  4555799.0\n",
       "44          2012                  utah   229463.0   671747.0\n",
       "45          2012               vermont   199259.0    92700.0\n",
       "46          2012              virginia  1905528.0  1789618.0\n",
       "47          2012            washington  1620432.0  1210369.0\n",
       "48          2012         west-virginia   234925.0   412406.0\n",
       "49          2012             wisconsin  1613950.0  1408746.0\n",
       "50          2012               wyoming    68780.0   170265.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for 2016, we'll be using Politico again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def voter_html_to_data_2016(voter_html):\n",
    "    blue_votes = int(voter_html.find(class_='type-democrat').find(class_='results-popular').get_text().replace(',',''))\n",
    "    red_votes = int(voter_html.find(class_='type-republican').find(class_='results-popular').get_text().replace(',',''))\n",
    "    return [blue_votes, red_votes]\n",
    "\n",
    "def get_voter_data_2016():\n",
    "    # Set up our data frame\n",
    "    df = pd.DataFrame(columns=('election_year', 'state', 'dem_votes', 'rep_votes'))\n",
    "    \n",
    "    # Base url we'll be getting data from\n",
    "    base_url = 'http://www.politico.com/2016-election/results/map/president/'\n",
    "    \n",
    "    # Get state names for url endings\n",
    "    state_urls = sorted([state.lower().replace(' ', '-') for state in states])\n",
    "    \n",
    "    # This time, Alaska and D.C. aren't different!\n",
    "    num_states = 0\n",
    "    for state in state_urls:\n",
    "        # Get data from site\n",
    "        response = requests.get(base_url + state + '/')\n",
    "        election_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        data = election_soup.select('section.content-group.election-intro')[0].find('div', class_='overall')\n",
    "        header_data = ['2016', state]\n",
    "        voter_data = header_data + voter_html_to_data_2016(data)\n",
    "        df.loc[num_states] = voter_data\n",
    "        num_states += 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_2016 = get_voter_data_2016()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>election_year</th>\n",
       "      <th>state</th>\n",
       "      <th>dem_votes</th>\n",
       "      <th>rep_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>alabama</td>\n",
       "      <td>718084.0</td>\n",
       "      <td>1306925.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>alaska</td>\n",
       "      <td>93007.0</td>\n",
       "      <td>130415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>arizona</td>\n",
       "      <td>936250.0</td>\n",
       "      <td>1021154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>arkansas</td>\n",
       "      <td>378729.0</td>\n",
       "      <td>677904.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>california</td>\n",
       "      <td>7362490.0</td>\n",
       "      <td>3916209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>colorado</td>\n",
       "      <td>1208095.0</td>\n",
       "      <td>1136354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>884432.0</td>\n",
       "      <td>668266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>delaware</td>\n",
       "      <td>235581.0</td>\n",
       "      <td>185103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>district-of-columbia</td>\n",
       "      <td>260223.0</td>\n",
       "      <td>11553.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>florida</td>\n",
       "      <td>4485745.0</td>\n",
       "      <td>4605515.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016</td>\n",
       "      <td>georgia</td>\n",
       "      <td>1837300.0</td>\n",
       "      <td>2068623.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016</td>\n",
       "      <td>hawaii</td>\n",
       "      <td>251853.0</td>\n",
       "      <td>121648.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016</td>\n",
       "      <td>idaho</td>\n",
       "      <td>189677.0</td>\n",
       "      <td>407199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016</td>\n",
       "      <td>illinois</td>\n",
       "      <td>2977498.0</td>\n",
       "      <td>2118179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016</td>\n",
       "      <td>indiana</td>\n",
       "      <td>1031953.0</td>\n",
       "      <td>1556220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016</td>\n",
       "      <td>iowa</td>\n",
       "      <td>650790.0</td>\n",
       "      <td>798923.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016</td>\n",
       "      <td>kansas</td>\n",
       "      <td>414788.0</td>\n",
       "      <td>656009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2016</td>\n",
       "      <td>kentucky</td>\n",
       "      <td>628834.0</td>\n",
       "      <td>1202942.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016</td>\n",
       "      <td>louisiana</td>\n",
       "      <td>779535.0</td>\n",
       "      <td>1178004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2016</td>\n",
       "      <td>maine</td>\n",
       "      <td>354873.0</td>\n",
       "      <td>334838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2016</td>\n",
       "      <td>maryland</td>\n",
       "      <td>1497951.0</td>\n",
       "      <td>873646.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2016</td>\n",
       "      <td>massachusetts</td>\n",
       "      <td>1964768.0</td>\n",
       "      <td>1083069.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016</td>\n",
       "      <td>michigan</td>\n",
       "      <td>2268193.0</td>\n",
       "      <td>2279805.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2016</td>\n",
       "      <td>minnesota</td>\n",
       "      <td>1366676.0</td>\n",
       "      <td>1322891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2016</td>\n",
       "      <td>mississippi</td>\n",
       "      <td>462001.0</td>\n",
       "      <td>678457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016</td>\n",
       "      <td>missouri</td>\n",
       "      <td>1054889.0</td>\n",
       "      <td>1585753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016</td>\n",
       "      <td>montana</td>\n",
       "      <td>174521.0</td>\n",
       "      <td>274120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2016</td>\n",
       "      <td>nebraska</td>\n",
       "      <td>273858.0</td>\n",
       "      <td>485819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016</td>\n",
       "      <td>nevada</td>\n",
       "      <td>537753.0</td>\n",
       "      <td>511319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2016</td>\n",
       "      <td>new-hampshire</td>\n",
       "      <td>348521.0</td>\n",
       "      <td>345789.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2016</td>\n",
       "      <td>new-jersey</td>\n",
       "      <td>2021756.0</td>\n",
       "      <td>1535513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2016</td>\n",
       "      <td>new-mexico</td>\n",
       "      <td>380724.0</td>\n",
       "      <td>315875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2016</td>\n",
       "      <td>new-york</td>\n",
       "      <td>4143874.0</td>\n",
       "      <td>2640570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2016</td>\n",
       "      <td>north-carolina</td>\n",
       "      <td>2162074.0</td>\n",
       "      <td>2339603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2016</td>\n",
       "      <td>north-dakota</td>\n",
       "      <td>93526.0</td>\n",
       "      <td>216133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2016</td>\n",
       "      <td>ohio</td>\n",
       "      <td>2317001.0</td>\n",
       "      <td>2771984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2016</td>\n",
       "      <td>oklahoma</td>\n",
       "      <td>419788.0</td>\n",
       "      <td>947934.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2016</td>\n",
       "      <td>oregon</td>\n",
       "      <td>934631.0</td>\n",
       "      <td>742506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2016</td>\n",
       "      <td>pennsylvania</td>\n",
       "      <td>2844705.0</td>\n",
       "      <td>2912941.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2016</td>\n",
       "      <td>rhode-island</td>\n",
       "      <td>249902.0</td>\n",
       "      <td>179421.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2016</td>\n",
       "      <td>south-carolina</td>\n",
       "      <td>849469.0</td>\n",
       "      <td>1143611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2016</td>\n",
       "      <td>south-dakota</td>\n",
       "      <td>117442.0</td>\n",
       "      <td>227701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2016</td>\n",
       "      <td>tennessee</td>\n",
       "      <td>867110.0</td>\n",
       "      <td>1517402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2016</td>\n",
       "      <td>texas</td>\n",
       "      <td>3867816.0</td>\n",
       "      <td>4681590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2016</td>\n",
       "      <td>utah</td>\n",
       "      <td>274188.0</td>\n",
       "      <td>452086.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2016</td>\n",
       "      <td>vermont</td>\n",
       "      <td>178179.0</td>\n",
       "      <td>95053.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2016</td>\n",
       "      <td>virginia</td>\n",
       "      <td>1916845.0</td>\n",
       "      <td>1731156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2016</td>\n",
       "      <td>washington</td>\n",
       "      <td>1610524.0</td>\n",
       "      <td>1129120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2016</td>\n",
       "      <td>west-virginia</td>\n",
       "      <td>187457.0</td>\n",
       "      <td>486198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2016</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>1382210.0</td>\n",
       "      <td>1409467.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2016</td>\n",
       "      <td>wyoming</td>\n",
       "      <td>55949.0</td>\n",
       "      <td>174248.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   election_year                 state  dem_votes  rep_votes\n",
       "0           2016               alabama   718084.0  1306925.0\n",
       "1           2016                alaska    93007.0   130415.0\n",
       "2           2016               arizona   936250.0  1021154.0\n",
       "3           2016              arkansas   378729.0   677904.0\n",
       "4           2016            california  7362490.0  3916209.0\n",
       "5           2016              colorado  1208095.0  1136354.0\n",
       "6           2016           connecticut   884432.0   668266.0\n",
       "7           2016              delaware   235581.0   185103.0\n",
       "8           2016  district-of-columbia   260223.0    11553.0\n",
       "9           2016               florida  4485745.0  4605515.0\n",
       "10          2016               georgia  1837300.0  2068623.0\n",
       "11          2016                hawaii   251853.0   121648.0\n",
       "12          2016                 idaho   189677.0   407199.0\n",
       "13          2016              illinois  2977498.0  2118179.0\n",
       "14          2016               indiana  1031953.0  1556220.0\n",
       "15          2016                  iowa   650790.0   798923.0\n",
       "16          2016                kansas   414788.0   656009.0\n",
       "17          2016              kentucky   628834.0  1202942.0\n",
       "18          2016             louisiana   779535.0  1178004.0\n",
       "19          2016                 maine   354873.0   334838.0\n",
       "20          2016              maryland  1497951.0   873646.0\n",
       "21          2016         massachusetts  1964768.0  1083069.0\n",
       "22          2016              michigan  2268193.0  2279805.0\n",
       "23          2016             minnesota  1366676.0  1322891.0\n",
       "24          2016           mississippi   462001.0   678457.0\n",
       "25          2016              missouri  1054889.0  1585753.0\n",
       "26          2016               montana   174521.0   274120.0\n",
       "27          2016              nebraska   273858.0   485819.0\n",
       "28          2016                nevada   537753.0   511319.0\n",
       "29          2016         new-hampshire   348521.0   345789.0\n",
       "30          2016            new-jersey  2021756.0  1535513.0\n",
       "31          2016            new-mexico   380724.0   315875.0\n",
       "32          2016              new-york  4143874.0  2640570.0\n",
       "33          2016        north-carolina  2162074.0  2339603.0\n",
       "34          2016          north-dakota    93526.0   216133.0\n",
       "35          2016                  ohio  2317001.0  2771984.0\n",
       "36          2016              oklahoma   419788.0   947934.0\n",
       "37          2016                oregon   934631.0   742506.0\n",
       "38          2016          pennsylvania  2844705.0  2912941.0\n",
       "39          2016          rhode-island   249902.0   179421.0\n",
       "40          2016        south-carolina   849469.0  1143611.0\n",
       "41          2016          south-dakota   117442.0   227701.0\n",
       "42          2016             tennessee   867110.0  1517402.0\n",
       "43          2016                 texas  3867816.0  4681590.0\n",
       "44          2016                  utah   274188.0   452086.0\n",
       "45          2016               vermont   178179.0    95053.0\n",
       "46          2016              virginia  1916845.0  1731156.0\n",
       "47          2016            washington  1610524.0  1129120.0\n",
       "48          2016         west-virginia   187457.0   486198.0\n",
       "49          2016             wisconsin  1382210.0  1409467.0\n",
       "50          2016               wyoming    55949.0   174248.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To aid in our analysis, we'll create a simple function to find the percent of the state that voted blue, given an election year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_percent_blue(state, year):\n",
    "    if year == 2008:\n",
    "        df = df_2008\n",
    "    elif year == 2012:\n",
    "        df = df_2012\n",
    "    else:\n",
    "        df = df_2016\n",
    "    df = df.set_index('state')\n",
    "    dem_votes = df.at[state,'dem_votes']\n",
    "    rep_votes = df.at[state, 'rep_votes']\n",
    "    return dem_votes / (dem_votes + rep_votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60713285679\n",
      "0.652778303597\n"
     ]
    }
   ],
   "source": [
    "print find_percent_blue('california', 2012)\n",
    "print find_percent_blue('california', 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll begin gathering data from the BLS, specifically, data regarding employment by state in the industries most negatively impacted by the recession (construction, manufacturing, and transportation/trade), as well as overall employment, in thousands of employees. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Scraping Labor Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json, string\n",
    "import requests, tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To utilize the Bureau of Labor Statistics Public API is unintuitive, to say the least. Essentially, each unique dataset that the BLS keeps has a serial ID that correesponds to it. Querying the data from the API involves figuring out exactly which dataset you want, and then translating that to a serial ID. The code below allows us to input requests in a reasonable format like JSON and have that get converted to the serial ID that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def opand(x,y): \n",
    "    return x and y\n",
    "\n",
    "\n",
    "def nest(keys, d_keys, d):\n",
    "    assert (len(keys) == len(d_keys))\n",
    "    iter_format = lambda (i, d_key) : \"for x%d in d['%s']\" % (i, d_key)\n",
    "    iters = string.join(map(iter_format, enumerate(d_keys)), sep=\" \")\n",
    "    arg_format = lambda (i) : '(\"' + keys[i] + '\", x' + str(i) + ')'\n",
    "    args = string.join(map(arg_format, range(len(keys))), sep=\", \")\n",
    "    return eval('[dict([' +  args +  ']) ' + iters + ']')\n",
    "\n",
    "\n",
    "def request(series):\n",
    "    \"\"\"\n",
    "    brief:\n",
    "        - requests series in batches of 15, returns list of json_data, \n",
    "          one for each request\n",
    "    args:\n",
    "        - series : list of bls series id's\n",
    "    \"\"\"\n",
    "    bls_url = 'http://api.bls.gov/publicAPI/v2/timeseries/data/'\n",
    "    regKeys = [\"bc2b9775e9794f37a23c0f6b2a4659b1\", \n",
    "               \"8874280f2cc142f3833754ad3cb6855c\",\n",
    "               \"dacaff7ea67b466685622348e9807f8f\"]\n",
    "    json_data = []\n",
    "    for i in tqdm.tqdm(range(0,len(series),50)):\n",
    "        headers = {'Content-type': 'application/json'}\n",
    "        data = json.dumps({\"seriesid\": series[i:i+50],\n",
    "                           \"startyear\":\"2004\", \n",
    "                           \"endyear\":\"2016\", \n",
    "                           \"registrationKey\":regKeys[2]})\n",
    "        try:\n",
    "            response = requests.post(bls_url, data=data, headers=headers)\n",
    "        except ConnectionError:\n",
    "            time.sleep(2)\n",
    "            response = requests.post(bls_url, data=data, headers=headers)\n",
    "        json_data.append(json.loads(response.text))\n",
    "    return json_data\n",
    "\n",
    "\n",
    "def format_series(config):\n",
    "    \"\"\"\n",
    "    brief:\n",
    "        - formats a request for data from the bls state and area employment, \n",
    "          hours, and earnings database if config['prefix'] == 'SM'\n",
    "\n",
    "        - formats a request for data from the bls local area unemployment \n",
    "          statistics database if config['prefix'] == 'SA'\n",
    "    args:\n",
    "        - config : {                   # http://www.bls.gov/help/hlpforma.htm#SM\n",
    "                    'prefix' : 'SM',\n",
    "                    'seasonal_adjustment' : 'S' or 'U',\n",
    "                    'state_code' : '01' to '50', \n",
    "                    'area_code' : '00000' to '99999',\n",
    "                    'supersector' : '00' to '99', \n",
    "                    'industry' : '000000' to '999999',     \n",
    "                    'datatype' : '00' to '99'              \n",
    "                    }\n",
    "                or {                   # http://www.bls.gov/help/hlpforma.htm#LA\n",
    "                    'prefix' : 'LA', \n",
    "                    'seasonal_adjustment' : 'S' or 'U',\n",
    "                    'area_type' : 'ST' or 'MT', \n",
    "                    'state_code' : '01' to '50',\n",
    "                    'area_code' : '000000000' or 'YYYYYYYYYYY'\n",
    "                    'measure': '03' to '06'\n",
    "                   }\n",
    "    \"\"\"\n",
    "    keys = dict({'SM' : ['prefix','seasonal_adjustment','state_code','area_code','supersector','industry','datatype'],\n",
    "                 'LA' : ['prefix', 'seasonal_adjustment','state_area_code', 'measure'],\n",
    "                 })\n",
    "    prefix = config['prefix']\n",
    "    return string.join([config[key] for key in keys[prefix]], sep=\"\")\n",
    "\n",
    "\n",
    "def make_series(config):\n",
    "    \"\"\"\n",
    "    brief:\n",
    "        - provided a dictionary of bls series id parameters,\n",
    "          construct and request each possible series_id given parameters\n",
    "    args:\n",
    "        - config : {\n",
    "                    'prefix' : ['SM'],\n",
    "                    'seasonal_adjustments' : ['S' or 'U'],\n",
    "                    'state_codes' : [string],\n",
    "                    'area_codes' : [{string -> string}],\n",
    "                    'supersectors' : [string],\n",
    "                    'industries' : [string],\n",
    "                    'datatypes' : [string]\n",
    "                    }\n",
    "                or {\n",
    "                    'prefix' : ['LA'],\n",
    "                    'seasonal_adjustment' : ['S' or 'U'],\n",
    "                    'area_types' : ['ST' or 'MT'],\n",
    "                    'state_codes' : ['01' to '50']\n",
    "                    'area_codes' : [{'ST', 'xx' --> 'STxx00000000000', \n",
    "                                    'MT', 'xx' --> 'MTxxYYYYYYYYYYY'}]\n",
    "                    'measures': [string]\n",
    "                   }\n",
    "    \"\"\"\n",
    "    keys = dict({'SM' : ['prefix','seasonal_adjustment','state_code','area_code','supersector','industry','datatype'],\n",
    "                 'LA' : ['prefix','seasonal_adjustment','state_area_code','measure'],\n",
    "                 })\n",
    "    param_keys = dict({'SM' : ['prefix','seasonal_adjustments','state_codes','area_codes','supersectors','industries','datatypes'],\n",
    "                       'LA' : ['prefix','seasonal_adjustments','state_area_codes','measures'],\n",
    "                       })\n",
    "    prefix = config['prefix'][0]\n",
    "    return [format_series(sid) for sid in nest(keys[prefix], param_keys[prefix], config)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, now we can actually use the API to get some useful information. Here, with a provided listed of metro codes (BLS codes corresponding to different metropolitan areas in the U.S.), and using those, we can construct queries to fetch various employment statistics from different states and metropolitan areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [405]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No JSON object could be decoded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-6e121559000c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mjson_data_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-87-2bfde5a12ee9>\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(series)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbls_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mjson_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/__init__.pyc\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/decoder.pyc\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \"\"\"\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/decoder.pyc\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No JSON object could be decoded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No JSON object could be decoded"
     ]
    }
   ],
   "source": [
    "config = {'prefix' : ['SM'],\n",
    "          'seasonal_adjustments' : ['S', 'U'],\n",
    "          'state_codes' : state_codes.values(),\n",
    "          'area_codes' : ['00000'],\n",
    "          'supersectors' : ['20', '30', '40', '50', '55', '00'],\n",
    "          'industries' : ['000000'],\n",
    "          'datatypes' : ['01'],\n",
    "          }\n",
    "           \n",
    "json_data_list = request(make_series(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've retrieved our data from the BLS API, we'll format it into the Pandas dataframes we'll be performing analyses on in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def series_id_to_state(series_id):\n",
    "    state_code_to_string = dict(zip(state_codes.values(), state_codes.keys()))\n",
    "    return state_code_to_string[str(series_id[3:5])]\n",
    "\n",
    "def series_id_to_industry(series_id):\n",
    "    industry_code_to_string = dict({'50' : 'information',\n",
    "                                    '55' : 'finance',\n",
    "                                    '20' : 'construction',\n",
    "                                    '30' : 'manufacturing',\n",
    "                                    '40' : 'transport_and_trade',\n",
    "                                    '00' : 'all',\n",
    "                                   })\n",
    "    return industry_code_to_string[series_id[10:12]]\n",
    "\n",
    "\n",
    "industry_data = dict({'information' : dict(zip(states, [defaultdict(list) for i in range(len(states))])),\n",
    "                      'finance' : dict(zip(states, [defaultdict(list) for i in range(len(states))])),\n",
    "                      'construction' : dict(zip(states, [defaultdict(list) for i in range(len(states))])),\n",
    "                      'manufacturing' : dict(zip(states, [defaultdict(list) for i in range(len(states))])),\n",
    "                      'transport_and_trade' : dict(zip(states, [defaultdict(list) for i in range(len(states))])),\n",
    "                      'all' : dict(zip(states, [defaultdict(list) for i in range(len(states))])),\n",
    "                      })\n",
    "\n",
    "# each json_data request has at between 1 <= # requests <= 50 in a list\n",
    "for json_data in json_data_list:\n",
    "    # each series in this list spans the years 2004:2016, and months 01:12\n",
    "    for json_series in json_data['Results']['series']:\n",
    "        series_id = json_series['seriesID']\n",
    "        # the state, and industry is constant for each series\n",
    "        state = series_id_to_state(series_id)\n",
    "        industry = series_id_to_industry(series_id)\n",
    "        # we want to average the values for each month for a given year\n",
    "        for year in years:\n",
    "            year_avg = []\n",
    "            for entry in json_series['data']:\n",
    "                if entry['year'] == year:\n",
    "                    year_avg.append(float(entry['value']))\n",
    "            year_avg = (0 if year_avg == [] else sum(year_avg) / len(year_avg))\n",
    "            industry_data[industry][state][year].append(year_avg)\n",
    "\n",
    "industry_dfs = dict()\n",
    "for industry in industries:\n",
    "    state_data = industry_data[industry]\n",
    "    for state in states:\n",
    "        year_data = state_data[state]\n",
    "        coalesce = lambda year : sum(year_data[year]) / len(year_data[year]) if year_data[year] != [] else 0\n",
    "        state_data[state] = [coalesce(year) for year in years]\n",
    "    industry_dfs[industry] = pd.DataFrame(data=state_data, index=years, columns=states).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "construction_df = industry_dfs['construction']\n",
    "manufacturing_df = industry_dfs['manufacturing']\n",
    "transport_and_trade_df = industry_dfs['transport_and_trade']\n",
    "total_employment_df = industry_dfs['all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "construction_df\n",
    "manufacturing_df\n",
    "transport_and_trade_df\n",
    "total_employment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all of our data is properly formatted, we can perform our analysis. In the next section, we manipulate the dataframes we created with the goal of predicting whether a state will be red or blue in 2016. We do this by training an SVC on the voter and employment datasets for 2008 and 2012 that we generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Employment Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we aggregate the employment of our blue collar industries into one big dataframe listing each state's blue collar employees in each election year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_blue_collar_df(construction, manufacturing, transport_trade):\n",
    "    df = pd.DataFrame({\n",
    "            \"state\": states,\n",
    "            2004: construction['2004'] + manufacturing['2004'] + transport_trade['2004'],\n",
    "            2008: construction['2008'] + manufacturing['2008'] + transport_trade['2008'],\n",
    "            2012: construction['2012'] + manufacturing['2012'] + transport_trade['2012'],\n",
    "            2016: construction['2016'] + manufacturing['2016'] + transport_trade['2016']\n",
    "        })\n",
    "    return df\n",
    "    \n",
    "blue_collar_df = create_blue_collar_df(construction_df, manufacturing_df, transport_and_trade_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use this dataframe and the total employment dataframe to make our SVM input dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_SVM_input(year, blue_collar_df, total_employment_df, df_4_years_ago):\n",
    "    df = pd.DataFrame({\"state\": states, \n",
    "                       \"blue_collar_change_last_8_years\": (blue_collar_df[year] - blue_collar_df[year - 8]) / blue_collar_df[year - 8],\n",
    "                       \"total_employment_change_last_8_years\": (total_employment_df[year] - total_employment_df[year - 8]) / total_employment_df[year - 8]})\n",
    "    df[\"proportion_blue_4_years_ago\"] = find_percent_blue(df[\"state\"], year)\n",
    "    return df\n",
    "\n",
    "df_predict_2012 = create_SVM_input(2012, blue_collar_df, total_employment_df, df_2008)\n",
    "df_predict_2016 = create_SVM_input(2016, blue_collar_df, total_employment_df, df_2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we label each state with its result (1 for Democrat, 0 for Republican) in each of the last 3 presidential elections (2008, 2012, 2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    'Alabama': [0,0,0], 'Alaska': [0,0,0],\n",
    "    'Arizona': [0,0,0], 'Arkansas': [0,0,0],\n",
    "    'California': [1,1,1], 'Colorado': [1,1,1],\n",
    "    'Connecticut': [1,1,1], 'Delaware': [1,1,1],\n",
    "    'District Of Columbia': [1,1,1], 'Florida': [1,1,0],\n",
    "    'Georgia': [0,0,0], 'Hawaii': [1,1,1],\n",
    "    'Idaho': [0,0,0], 'Illinois': [1,1,1],\n",
    "    'Indiana': [1,0,0], 'Iowa': [1,1,0],\n",
    "    'Kansas': [0,0,0], 'Kentucky': [0,0,0],\n",
    "    'Louisiana': [0,0,0], 'Maine': [1,1,1],\n",
    "    'Maryland': [1,1,1],'Massachusetts': [1,1,1],\n",
    "    'Michigan': [1,1,0],'Minnesota': [1,1,1],\n",
    "    'Mississippi': [0,0,0], 'Missouri': [0,0,0],\n",
    "    'Montana': [0,0,0], 'Nebraska': [0,0,0],\n",
    "    'Nevada': [1,1,1], 'New Hampshire': [1,1,1],\n",
    "    'New Jersey': [1,1,1],'New Mexico': [1,1,1],\n",
    "    'New York': [1,1,1], 'North Carolina': [1,0,0],\n",
    "    'North Dakota': [0,0,0],'Ohio': [1,1,0],    \n",
    "    'Oklahoma': [0,0,0],'Oregon': [1,1,1],\n",
    "    'Pennsylvania': [1,1,0],'Rhode Island': [1,1,1],\n",
    "    'South Carolina': [0,0,0],'South Dakota': [0,0,0],\n",
    "    'Tennessee': [0,0,0],'Texas': [0,0,0],\n",
    "    'Utah': [0,0,0], 'Vermont': [1,1,1],\n",
    "    'Virginia': [1,1,1],'Washington': [1,1,1],\n",
    "    'West Virginia': [0,0,0], 'Wisconsin': [1,1,0],\n",
    "    'Wyoming': [0,0,0]\n",
    "}\n",
    "\n",
    "def provide_labels(year):\n",
    "    return np.array([v[(year - 2008) / 4] for k, v in results.iteritems()])\n",
    "    \n",
    "# df_predict_2012[\"alphabetical_state_results_2008\"] = provide_labels(2008)\n",
    "df_predict_2012[\"alphabetical_state_results_2012\"] = provide_labels(2012)\n",
    "df_predict_2016[\"alphabetical_state_results_2016\"] = provide_labels(2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've extracted all the necessary training data, we train an SVM on the features and labels of our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# classifier for training examples, which are 2012 states and labels\n",
    "def learn_classifier(training_features, training_labels):\n",
    "    svc = sklearn.svm.SVC()\n",
    "    return svc.fit(training_features, training_labels)\n",
    "\n",
    "trained_svc_industry_to_total = learn_classifier(df_predict_2012[\"blue_collar_change_last_8_years\", \n",
    "                                               \"total_employment_change_last_8_years\"], \n",
    "                               df_predict_2012[\"alphabetical_state_results_2012\"])\n",
    "\n",
    "trained_svc_industry_to_vote = learn_classifier(df_predict_2012[\"blue_collar_change_last_8_years\",\n",
    "                                               \"proportion_blue_4_years_ago\"], \n",
    "                               df_predict_2012[\"alphabetical_state_results_2012\"])\n",
    "\n",
    "trained_svc_total_to_vote = learn_classifier(df_predict_2012[\"total_employment_change_last_8_years\", \n",
    "                                               \"proportion_blue_4_years_ago\"], \n",
    "                               df_predict_2012[\"alphabetical_state_results_2012\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run our classifier on our testing set, the states in the 2016 election."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval_classifier(svc, testing_features, testing_labels):\n",
    "    predicted_labels = svc.predict(testing_features)\n",
    "    return float(np.sum(predicted_labels == testing_labels)) / testing_features.shape[0]\n",
    "\n",
    "accuracy_industry_to_total = eval_classifier(trained_svc_industry_to_total, df_predict_2016[\"blue_collar_change_last_8_years\", \n",
    "                                                        \"total_employment_change_last_8_years\"], \n",
    "                           df[\"alphabetical_state_results_2016\"])\n",
    "\n",
    "accuracy_industry_to_vote = eval_classifier(trained_svc_industry_to_vote, df_predict_2016[\"blue_collar_change_last_8_years\",\n",
    "                                                        \"proportion_blue_4_years_ago\"], \n",
    "                           df[\"alphabetical_state_results_2016\"])\n",
    "\n",
    "accuracy_total_to_vote = eval_classifier(trained_svc_total_to_vote, df_predict_2016[\"total_employment_change_last_8_years\", \n",
    "                                                        \"proportion_blue_4_years_ago\"], \n",
    "                           df[\"alphabetical_state_results_2016\"])\n",
    "\n",
    "\n",
    "print accuracy_industry_to_total, accuracy_industry_to_vote, accuracy_total_to_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
