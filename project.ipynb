{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our project, we would like to collect data to see if voter preferences correlate to how affected certain populations were by the Great Recession. We can measure “recession effect” in a number of different ways. For example, we can use statistics from the US Bureau of Labor to map certain geographical areas, and we can compare statistics from pre-2008 and post-2008 to view how the recession affected jobs in those regions. From there, we could look at polls or voter data to see how those regions voted in either the 2010 midterm elections or the 2012 Presidential election. Comparing these two sets of data, we would be interested in finding out which parties/administrations people blamed more for the recession, and whether or not voting habits changed in areas most affected by the recession, and why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sounds good, but because political landscapes are changing constantly, it is difficult to assign certain changes as being \"caused\" to the 2008 recession as opposed to just brought on by other factors that happen to correlate with areas hit by the recession (the classic correlation/causation issue). But if you keep this fact in mind, then I think the analysis can be interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. recession effect data\n",
    "\t- industries effected by 08’ recession\n",
    "\t- recovery rate of effected industries (pre ’08 / post ’08 industry stats)\n",
    "\t- outsourcing in respective industries\n",
    "    - [BLS api](http://www.bls.gov/developers/api_signature_v2.htm#multiple)\n",
    "    - [BLS series](http://www.bls.gov/help/hlpforma.htm#OE)\n",
    "2. voter preference data\n",
    "\t-  pre / post ’08\n",
    "3. find way to partition each data set geographically\n",
    "\t- west coast / midwest / east coast\n",
    "\t- rural / metropolitan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Election"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze the election data, we'll be looking towards [Politico](http://www.politico.com/) and the [New York Times](http://www.nytimes.com) and their election coverage pages. Unfortunately, due to formatting changes over the years, it's a little more difficult than we'd like it to be to fetch county voter data from the 2008, 2012, and 2016 elections with one script. However, it's not too hard to write scripts for each of those elections individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# List of states and D.C.\n",
    "states = [\n",
    "    'Alabama','Alaska','Arizona','Arkansas','California','Colorado',\n",
    "    'Connecticut','Delaware','District Of Columbia','Florida','Georgia','Hawaii','Idaho', \n",
    "    'Illinois','Indiana','Iowa','Kansas','Kentucky','Louisiana',\n",
    "    'Maine','Maryland','Massachusetts','Michigan','Minnesota',\n",
    "    'Mississippi', 'Missouri','Montana','Nebraska','Nevada',\n",
    "    'New Hampshire','New Jersey','New Mexico','New York',\n",
    "    'North Carolina','North Dakota','Ohio',    \n",
    "    'Oklahoma','Oregon','Pennsylvania','Rhode Island',\n",
    "    'South Carolina','South Dakota','Tennessee','Texas','Utah',\n",
    "    'Vermont','Virginia','Washington','West Virginia',\n",
    "    'Wisconsin','Wyoming'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Converts data taken from the table in the html\n",
    "    Input: a table row of voting data, in html\n",
    "    Output: a list of data in a more desirable format\n",
    "'''\n",
    "def voter_html_to_data(voter_html):\n",
    "    data = [datum.get_text().strip() for datum in voter_html.find_all('td')]\n",
    "    # For the 2008 elections, the data list will be in the following format:\n",
    "    # County name, % votes for Obama, Votes for Obama, % votes for McCain, Votes for McCain\n",
    "    # For simplicity's sake, we'll calculate the percentages ourselves based on the raw vote counts\n",
    "    county_name = data[0].lower()\n",
    "    blue_votes = int(data[2][:-5].replace(',',''))\n",
    "    red_votes = int(data[4][:-5].replace(',',''))\n",
    "    blue_percentage = float(blue_votes) / (blue_votes + red_votes)\n",
    "    red_percentage = float(red_votes) / (blue_votes + red_votes)\n",
    "    return [county_name, blue_votes, blue_percentage, red_votes, red_percentage]\n",
    "\n",
    "def get_voter_data_2008():\n",
    "    # Set up our data frame\n",
    "    df = pd.DataFrame(columns=('election_year', 'state', 'county', 'dem_votes', 'dem_percentage', 'rep_votes', 'rep_percentage'))\n",
    "    \n",
    "    # Base url we'll be getting data from \n",
    "    base_url = 'http://elections.nytimes.com/2008/results/states/president/'\n",
    "    \n",
    "    # Get state names for url endings\n",
    "    state_urls = sorted([state.lower().replace(' ', '-') for state in states])\n",
    "\n",
    "    # Iterate through the states (except for Alaska and D.C.)\n",
    "    num_counties = 0\n",
    "    for state in state_urls:\n",
    "        if state != 'alaska' and state != 'district-of-columbia':\n",
    "            # Get data from the site\n",
    "            response = requests.get(base_url + state + '.html')\n",
    "            election_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Data for all states except for Alaska and D.C.\n",
    "            data_rows = election_soup.find(id='winners-by-county-table').tbody.find_all('tr')\n",
    "            \n",
    "            # Data that every row will have (election year and state)\n",
    "            header_data = ['2008', state]\n",
    "            for row in data_rows:\n",
    "                voter_data = header_data + voter_html_to_data(row)\n",
    "                df.loc[num_counties] = voter_data\n",
    "                num_counties += 1\n",
    "    \n",
    "    # Since Alaska and D.C. don't have counties, we process them slightly differently\n",
    "    # First, Alaska\n",
    "    alaska_html = requests.get('http://elections.nytimes.com/2008/results/states/alaska.html')\n",
    "    alaska_election_soup = BeautifulSoup(alaska_html.text, 'html.parser')\n",
    "    \n",
    "    alaska_obama = alaska_election_soup.find(id='presidential-results-table').tbody.find_all('tr')[:2][1].find_all('td')\n",
    "    alaska_mccain = alaska_election_soup.find(id='presidential-results-table').tbody.find_all('tr')[:2][0].find_all('td')\n",
    "    alaska_blue_votes = int(alaska_obama[1].get_text().strip().replace(',',''))\n",
    "    alaska_red_votes = int(alaska_mccain[2].get_text().strip().replace(',',''))\n",
    "    alaska_blue_percent = float(alaska_blue_votes) / (alaska_blue_votes + alaska_red_votes)\n",
    "    alaska_red_percent = float(alaska_red_votes) / (alaska_blue_votes + alaska_red_votes)\n",
    "    alaska_data = ['2008', 'alaska', 'alaska', alaska_blue_votes, alaska_blue_percent, alaska_red_votes, alaska_red_percent]\n",
    "    df.loc[num_counties] = alaska_data\n",
    "    num_counties += 1\n",
    "    \n",
    "    # Finally, D.C.\n",
    "    dc_html = requests.get('http://elections.nytimes.com/2008/results/states/district-of-columbia.html')\n",
    "    dc_election_soup = BeautifulSoup(dc_html.text, 'html.parser')\n",
    "\n",
    "    dc_obama = dc_election_soup.find(id='presidential-results-table').tbody.find_all('tr')[:2][0].find_all('td')\n",
    "    dc_mccain = dc_election_soup.find(id='presidential-results-table').tbody.find_all('tr')[:2][1].find_all('td')\n",
    "    dc_blue_votes = int(dc_obama[2].get_text().strip().replace(',',''))\n",
    "    dc_red_votes = int(dc_mccain[1].get_text().strip().replace(',',''))\n",
    "    dc_blue_percent = float(dc_blue_votes) / (dc_blue_votes + dc_red_votes)\n",
    "    dc_red_percent = float(dc_red_votes) / (dc_blue_votes + dc_red_votes)\n",
    "    dc_data = ['2008', 'district-of-columbia', 'district-of-columbia', dc_blue_votes, dc_blue_percent, dc_red_votes, dc_red_percent]\n",
    "    df.loc[num_counties] = dc_data\n",
    "    num_counties += 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     election_year                 state                county  dem_votes  \\\n",
      "0             2008               alabama               autauga     6091.0   \n",
      "1             2008               alabama               baldwin    19362.0   \n",
      "2             2008               alabama               barbour     5685.0   \n",
      "3             2008               alabama                  bibb     2289.0   \n",
      "4             2008               alabama                blount     3518.0   \n",
      "5             2008               alabama               bullock     4001.0   \n",
      "6             2008               alabama                butler     4174.0   \n",
      "7             2008               alabama               calhoun    16325.0   \n",
      "8             2008               alabama              chambers     6782.0   \n",
      "9             2008               alabama              cherokee     2299.0   \n",
      "10            2008               alabama               chilton     3666.0   \n",
      "11            2008               alabama               choctaw     3633.0   \n",
      "12            2008               alabama                clarke     5907.0   \n",
      "13            2008               alabama                  clay     1722.0   \n",
      "14            2008               alabama              cleburne     1166.0   \n",
      "15            2008               alabama                coffee     5068.0   \n",
      "16            2008               alabama               colbert     9698.0   \n",
      "17            2008               alabama               conecuh     3411.0   \n",
      "18            2008               alabama                 coosa     2269.0   \n",
      "19            2008               alabama             covington     3238.0   \n",
      "20            2008               alabama              crenshaw     1938.0   \n",
      "21            2008               alabama               cullman     5855.0   \n",
      "22            2008               alabama                  dale     5257.0   \n",
      "23            2008               alabama                dallas    13958.0   \n",
      "24            2008               alabama                dekalb     5654.0   \n",
      "25            2008               alabama                elmore     8268.0   \n",
      "26            2008               alabama              escambia     5176.0   \n",
      "27            2008               alabama                etowah    13480.0   \n",
      "28            2008               alabama               fayette     1988.0   \n",
      "29            2008               alabama              franklin     3469.0   \n",
      "...            ...                   ...                   ...        ...   \n",
      "3084          2008             wisconsin              waukesha    85248.0   \n",
      "3085          2008             wisconsin               waupaca    12952.0   \n",
      "3086          2008             wisconsin              waushara     5868.0   \n",
      "3087          2008             wisconsin             winnebago    48156.0   \n",
      "3088          2008             wisconsin                  wood    21705.0   \n",
      "3089          2008               wyoming                albany     8618.0   \n",
      "3090          2008               wyoming              big horn     1108.0   \n",
      "3091          2008               wyoming              campbell     2986.0   \n",
      "3092          2008               wyoming                carbon     2336.0   \n",
      "3093          2008               wyoming              converse     1380.0   \n",
      "3094          2008               wyoming                 crook      612.0   \n",
      "3095          2008               wyoming               fremont     6016.0   \n",
      "3096          2008               wyoming                goshen     1832.0   \n",
      "3097          2008               wyoming           hot springs      618.0   \n",
      "3098          2008               wyoming               johnson      908.0   \n",
      "3099          2008               wyoming               laramie    16070.0   \n",
      "3100          2008               wyoming               lincoln     1823.0   \n",
      "3101          2008               wyoming               natrona     8144.0   \n",
      "3102          2008               wyoming              niobrara      244.0   \n",
      "3103          2008               wyoming                  park     3757.0   \n",
      "3104          2008               wyoming                platte     1407.0   \n",
      "3105          2008               wyoming              sheridan     4450.0   \n",
      "3106          2008               wyoming              sublette      936.0   \n",
      "3107          2008               wyoming            sweetwater     5762.0   \n",
      "3108          2008               wyoming                 teton     7472.0   \n",
      "3109          2008               wyoming                 uinta     2317.0   \n",
      "3110          2008               wyoming              washakie     1042.0   \n",
      "3111          2008               wyoming                weston      658.0   \n",
      "3112          2008                alaska                alaska   122485.0   \n",
      "3113          2008  district-of-columbia  district-of-columbia   210403.0   \n",
      "\n",
      "      dem_percentage  rep_votes  rep_percentage  \n",
      "0           0.259313    17398.0        0.740687  \n",
      "1           0.240361    61192.0        0.759639  \n",
      "2           0.492336     5862.0        0.507664  \n",
      "3           0.268158     6247.0        0.731842  \n",
      "4           0.147320    20362.0        0.852680  \n",
      "5           0.742301     1389.0        0.257699  \n",
      "6           0.432718     5472.0        0.567282  \n",
      "7           0.335553    32326.0        0.664447  \n",
      "8           0.456947     8060.0        0.543053  \n",
      "9           0.239879     7285.0        0.760121  \n",
      "10          0.208295    13934.0        0.791705  \n",
      "11          0.462626     4220.0        0.537374  \n",
      "12          0.442075     7455.0        0.557925  \n",
      "13          0.258248     4946.0        0.741752  \n",
      "14          0.183046     5204.0        0.816954  \n",
      "15          0.253692    14909.0        0.746308  \n",
      "16          0.397020    14729.0        0.602980  \n",
      "17          0.496362     3461.0        0.503638  \n",
      "18          0.411498     3245.0        0.588502  \n",
      "19          0.206650    12431.0        0.793350  \n",
      "20          0.309882     4316.0        0.690118  \n",
      "21          0.168771    28837.0        0.831229  \n",
      "22          0.274804    13873.0        0.725196  \n",
      "23          0.672707     6791.0        0.327293  \n",
      "24          0.239526    17951.0        0.760474  \n",
      "25          0.243441    25695.0        0.756559  \n",
      "26          0.355959     9365.0        0.644041  \n",
      "27          0.306071    30562.0        0.693929  \n",
      "28          0.252830     5875.0        0.747170  \n",
      "29          0.301207     8048.0        0.698793  \n",
      "...              ...        ...             ...  \n",
      "3084        0.370101   145089.0        0.629899  \n",
      "3085        0.516366    12131.0        0.483634  \n",
      "3086        0.504254     5769.0        0.495746  \n",
      "3087        0.559310    37943.0        0.440690  \n",
      "3088        0.566991    16576.0        0.433009  \n",
      "3089        0.519188     7981.0        0.480812  \n",
      "3090        0.215104     4043.0        0.784896  \n",
      "3091        0.186777    13001.0        0.813223  \n",
      "3092        0.350382     4331.0        0.649618  \n",
      "3093        0.218909     4924.0        0.781091  \n",
      "3094        0.170997     2967.0        0.829003  \n",
      "3095        0.351854    11082.0        0.648146  \n",
      "3096        0.317284     3942.0        0.682716  \n",
      "3097        0.252039     1834.0        0.747961  \n",
      "3098        0.214050     3334.0        0.785950  \n",
      "3099        0.395628    24549.0        0.604372  \n",
      "3100        0.219427     6485.0        0.780573  \n",
      "3101        0.316678    17573.0        0.683322  \n",
      "3102        0.193497     1017.0        0.806503  \n",
      "3103        0.257417    10838.0        0.742583  \n",
      "3104        0.319773     2993.0        0.680227  \n",
      "3105        0.304398    10169.0        0.695602  \n",
      "3106        0.220132     3316.0        0.779868  \n",
      "3107        0.357400    10360.0        0.642600  \n",
      "3108        0.620650     4567.0        0.379350  \n",
      "3109        0.286899     5759.0        0.713101  \n",
      "3110        0.260630     2956.0        0.739370  \n",
      "3111        0.200855     2618.0        0.799145  \n",
      "3112        0.388698   192631.0        0.611302  \n",
      "3113        0.934194    14821.0        0.065806  \n",
      "\n",
      "[3114 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df = get_voter_data_2008()\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
